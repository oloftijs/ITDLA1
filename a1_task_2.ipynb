{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bd2523a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow import keras\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933e542a",
   "metadata": {},
   "source": [
    "# Task 1: Learn the basics of Keras API for TensorFlow.\n",
    "\n",
    "Start with reading the section “Implementing MLPs with Keras” from Chapter 10 of Geron’s textbook\n",
    "(pages 295-320). Then install TensorFlow 2.0+ and experiment with the code included in this section\n",
    "(Brightspace General information → Instructions). Additionally, study the official documentation https:\n",
    "//keras.io/ and get an idea of the numerous options offered by Keras (layers, loss functions, metrics,\n",
    "optimizers, activations, initializers, regularizers). Don’t get overwhelmed with the number of options – you\n",
    "will frequently return to this site in the coming months."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc84169c",
   "metadata": {},
   "source": [
    "Check out this official repository with many examples of Keras implementations of various sorts of\n",
    "deep neural networks here. We recommend cloning this repository and trying to get some of these\n",
    "examples running on your system (or Colab/DeepNote). In particular, experiment with mnist mlp.py\n",
    "and mnist cnn.py scripts which show you how to build simple neural networks for the MNIST dataset\n",
    "(useful for the next task).\n",
    "\n",
    "Next, take the two well-known datasets: Fashion MNIST (introduced in Ch 10, p. 298) and CIFAR-10.\n",
    "The first dataset contains 2D (grayscale) images of size 28x28, split into 10 categories; 60,000 images\n",
    "for training and 10,000 for testing, while the latter contains 32x32x3 RGB images (50,000/10,000\n",
    "train/test). Apply two reference networks on the fashion MNIST dataset. \n",
    "\n",
    "Experiment with both networks, trying various options: initializations, activations, optimizers (and\n",
    "their hyperparameters), regularizations (L1, L2, Dropout, no Dropout). You may also experiment\n",
    "with changing the architecture of both networks: adding/removing layers, number of convolutional\n",
    "filters, their sizes, etc. For optimizing your hyperparameters you should use a validation set (10% of\n",
    "the training set). After you have found the best-performing hyperparameter sets, take the 3 best ones\n",
    "and train new models on the CIFAR-10 dataset to see whether your performance gains translate to a\n",
    "different dataset. Provide your thoughts on these results in the report (e.g. what are the main reasons\n",
    "for the difference in performance?).\n",
    "\n",
    "The purpose of this task is NOT to get the highest accuracy. Instead, you are supposed to gain some\n",
    "practical experience with tuning networks, running multiple experiments (with the help of some scripting),\n",
    "and, very importantly, documenting your findings and understanding reasonable ranges for your hyperparameters. In your report, you have to provide a concise description of your experiments, results, and conclusions.\n",
    "The quality of your work (code and report) is more important than the quantity or the accuracy you’ve\n",
    "achieved.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b99971",
   "metadata": {},
   "source": [
    "## (a) A multi-layer perceptron described in detail in Ch. 10, pp. 299-307"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2afdfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import the fashion MNIST dataset.\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "X_test = X_test/255.0\n",
    "X_valid, X_train = X_train_full[:5000]/255.0, X_train_full[5000:]/255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4459a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Input((28,28)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(300, activation='elu'))\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3936022e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_12\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_12\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">235,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">30,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_12 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │       \u001b[38;5;34m235,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m30,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,010\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m266,610\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m266,610\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219cd6d1",
   "metadata": {},
   "source": [
    "## (b) After lecture 6/7: a convolutional neural network described in Ch. 14, p. 447."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498542d3",
   "metadata": {},
   "source": [
    "# Task 2: Develop a “Tell-the-time” network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7d263b",
   "metadata": {},
   "source": [
    "## 1\n",
    "\n",
    "The problem of correctly telling the time can be formulated either as a multi-class classification\n",
    "problem (for example, with 12x60=720 classes representing each minute label) or a regression problem\n",
    "(for example, predicting the number of minutes after 12 o’clock). Therefore, your goal is to come up\n",
    "with different representations for the labels of your data adapt the output layer of your neural network\n",
    "and see how it impacts the training time and performance. No matter which architecture and loss\n",
    "function you will use when reporting results also provide “common sense” accuracy: the absolute value\n",
    "of the time difference between the predicted and the actual time (e.g., the “common sense” difference\n",
    "between “predicted” 11:55 and the “target” 0:05 is just 10 minutes and not 11 hours and 50 minutes!).\n",
    "Minimizing this “common sense” error measure is the main objective of this assignment! Notice that\n",
    "it is a common situation in Machine Learning: we often train models using one error measure (e.g.,\n",
    "cross-entropy loss) while the actual performance measure that we are interested in is different, e.g., the\n",
    "accuracy (the percentage of correctly classified cases)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192faa0b",
   "metadata": {},
   "source": [
    "The dataset can be downloaded from here and it consists of 18000 grayscale images (18000x150x150\n",
    "or 18000x75x75) contained in ‘images.npy’. The labels for each sample are represented by two integers\n",
    "(18000x2, ‘labels.npy’ file), that correspond to the hour and minute displayed by the clock. You can see\n",
    "that each image is rendered from a different angle and rotation and they might contain light reflections from\n",
    "within the scene making this a non-trivial problem. For your experiments, we suggest splitting your data\n",
    "into 80/10/10% splits for training/validation and test sets respectively. Remember to shuffle your dataset\n",
    "as the sample files are ordered. We suggest using the smaller dataset for your initial tests and runs (75x75\n",
    "images) and then reporting your results on the larger (150x150) datase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ad866b",
   "metadata": {},
   "source": [
    "### (a) Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd90345d",
   "metadata": {},
   "source": [
    "Treat this as a n-class classification problem. We suggest starting out with a\n",
    "smaller number of categories e.g. grouping all the samples that are between [3 : 00 − 3 : 30] into\n",
    "a single category (results in 24 categories in total), and trying to train a CNN model. Once you\n",
    "have found a working architecture, increase the number of categories by using smaller intervals\n",
    "for grouping samples to increase the ’common sense accuracy’. Can you train a network using\n",
    "all 720 different labels? What problems does such a label representation have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421d4afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.20.0\n",
      "TensorFlow detected 1 GPU(s):\n",
      "  - /physical_device:GPU:0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a49a8dc3",
   "metadata": {},
   "source": [
    "#### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f46e7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"A1_data_75\"\n",
    "images_path = os.path.join(data_folder, \"images.npy\")\n",
    "images = np.load(images_path)\n",
    "labels_path = os.path.join(data_folder, \"labels.npy\")\n",
    "labels = np.load(labels_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c526553d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "599be172",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0df874d1",
   "metadata": {},
   "source": [
    "(a) Classification - treat this as a n-class classification problem. We suggest starting out with a\n",
    "smaller number of categories e.g. grouping all the samples that are between [3 : 00 −3 : 30] into\n",
    "a single category (results in 24 categories in total), and trying to train a CNN model. Once you\n",
    "have found a working architecture, increase the number of categories by using smaller intervals\n",
    "for grouping samples to increase the ’common sense accuracy’. Can you train a network using\n",
    "all 720 different labels? What problems does such a label representation have?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d05f0fd",
   "metadata": {},
   "source": [
    "## Task a: classification\n",
    "We will start with deviding labels into 24 categories, one for each 30 minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b7cc7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0]\n",
      " [ 0  0]\n",
      " [ 0  0]\n",
      " ...\n",
      " [11 59]\n",
      " [11 59]\n",
      " [11 59]]\n",
      "[ 0  0  0 ... 23 23 23]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(labels)\n",
    "def get_cat_labels(labels):\n",
    "    new_labels = []\n",
    "    for label in labels:\n",
    "        label = label[0]* 2 + int(label[1] >= 30)\n",
    "        new_labels.append(label)\n",
    "    return np.array(new_labels)\n",
    "labels = get_cat_labels(labels)\n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a59933",
   "metadata": {},
   "source": [
    "We then split the data into training, validation, and test sets. The sklearn train_test_split method shuffles the data by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0460928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (14400, 75, 75)\n",
      "y_train shape: (14400,)\n",
      "X_valid shape: (1800, 75, 75)\n",
      "y_valid shape: (1800,)\n",
      "X_test shape: (1800, 75, 75)\n",
      "y_test shape: (1800,)\n"
     ]
    }
   ],
   "source": [
    "X_train_full, X_test,y_train_full, y_test = train_test_split(\n",
    "    images, labels, test_size=0.1, random_state=35\n",
    ")\n",
    "X_train, X_valid,y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=1/9, random_state=35\n",
    ") # 1/9 x 0.9 = 0.1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0363c8",
   "metadata": {},
   "source": [
    "we define a common sense loss. This will calculate how far of the prediction was"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2865ea1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_sense_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    y_pred_class = tf.argmax(y_pred, axis=1)\n",
    "    y_true_float = tf.cast(tf.squeeze(y_true), dtype=tf.float32)\n",
    "    y_pred_float = tf.cast(y_pred_class, dtype=tf.float32)\n",
    "    diff = tf.abs(y_true_float - y_pred_float)\n",
    "    cyclical_diff = tf.minimum(diff, 12.0 - diff)\n",
    "    print(cyclical_diff)\n",
    "    return tf.reduce_mean(cyclical_diff)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2e45f7",
   "metadata": {},
   "source": [
    "Our model for 24 class classification. We use a scheduler to lower the learning rate when we plateau\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fb4aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lr_scheduler = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,          # halve the learning rate if there is no improvement\n",
    "    patience=3,          # Wait 2 epochs with no improvement before reducing\n",
    "    min_lr=1e-6          # Set a minimum learning rate at 1e-6\n",
    ")\n",
    "early_stopper = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=6,          # Wait 6 epochs for improvement before stopping\n",
    "    restore_best_weights=True  # Automatically restore the weights from the best epoch\n",
    ")\n",
    "model = keras.models.Sequential([\n",
    "    keras.Input(shape=(75, 75, 1)),\n",
    "    # Block 1\n",
    "    keras.layers.Conv2D(32, (3,3), activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    # Block 2\n",
    "    keras.layers.Conv2D(64, (3,3), activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(64, (3,3), activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPooling2D(2),\n",
    "\n",
    "    # Block 3\n",
    "    keras.layers.Conv2D(128, (3,3), activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(128, (3,3), activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPooling2D(2), # Output shape: (9, 9, 128)\n",
    "\n",
    "    # Block 4\n",
    "    keras.layers.Conv2D(256, (3,3), activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPooling2D(2), # Output shape: (4, 4, 256)\n",
    "\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128, activation=\"leaky_relu\"),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(64, activation=\"leaky_relu\"),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(24, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "metrics=[common_sense_loss,\"Accuracy\"\n",
    "        #   tf.keras.metrics.Precision(), tf.keras.metrics.Recall()\n",
    "          ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d76ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - Accuracy: 0.9581 - common_sense_loss: 0.0559 - loss: 0.1244 - val_Accuracy: 0.9578 - val_common_sense_loss: 0.0351 - val_loss: 0.1369 - learning_rate: 3.1250e-05\n",
      "Epoch 2/10\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - Accuracy: 0.9596 - common_sense_loss: 0.0474 - loss: 0.1199 - val_Accuracy: 0.9594 - val_common_sense_loss: 0.0389 - val_loss: 0.1259 - learning_rate: 3.1250e-05\n",
      "Epoch 3/10\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - Accuracy: 0.9624 - common_sense_loss: 0.0453 - loss: 0.1182 - val_Accuracy: 0.9517 - val_common_sense_loss: 0.0515 - val_loss: 0.1607 - learning_rate: 3.1250e-05\n",
      "Epoch 4/10\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - Accuracy: 0.9633 - common_sense_loss: 0.0463 - loss: 0.1117 - val_Accuracy: 0.9589 - val_common_sense_loss: 0.0417 - val_loss: 0.1299 - learning_rate: 3.1250e-05\n",
      "Epoch 5/10\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - Accuracy: 0.9642 - common_sense_loss: 0.0422 - loss: 0.1092 - val_Accuracy: 0.9594 - val_common_sense_loss: 0.0482 - val_loss: 0.1330 - learning_rate: 1.5625e-05\n",
      "Epoch 6/10\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - Accuracy: 0.9665 - common_sense_loss: 0.0440 - loss: 0.0996 - val_Accuracy: 0.9628 - val_common_sense_loss: 0.0378 - val_loss: 0.1279 - learning_rate: 1.5625e-05\n",
      "Epoch 7/10\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - Accuracy: 0.9651 - common_sense_loss: 0.0481 - loss: 0.1046 - val_Accuracy: 0.9667 - val_common_sense_loss: 0.0351 - val_loss: 0.1242 - learning_rate: 7.8125e-06\n",
      "Epoch 8/10\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - Accuracy: 0.9706 - common_sense_loss: 0.0360 - loss: 0.0927 - val_Accuracy: 0.9644 - val_common_sense_loss: 0.0384 - val_loss: 0.1248 - learning_rate: 7.8125e-06\n",
      "Epoch 9/10\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - Accuracy: 0.9678 - common_sense_loss: 0.0418 - loss: 0.0954 - val_Accuracy: 0.9650 - val_common_sense_loss: 0.0444 - val_loss: 0.1275 - learning_rate: 7.8125e-06\n",
      "Epoch 10/10\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - Accuracy: 0.9688 - common_sense_loss: 0.0388 - loss: 0.0968 - val_Accuracy: 0.9633 - val_common_sense_loss: 0.0400 - val_loss: 0.1261 - learning_rate: 3.9063e-06\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - Accuracy: 0.9711 - common_sense_loss: 0.0252 - loss: 0.1144\n",
      "Test accuracy: 0.9711111187934875\n",
      "2.20.0\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=10,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=[lr_scheduler, early_stopper]\n",
    "    )\n",
    "#evaluate the model on the test set\n",
    "test_loss,test_csl, test_acc = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', test_acc)\n",
    "#base:0.8420000076293945\n",
    "#leaky: 0.8525000214576721\n",
    "#leaky + L2regularization: 0.8472999930381775\n",
    "#leaky + batch normalization: 0.8978000283241272\n",
    "\n",
    "(print(tf.__version__))\n",
    "#0.9711111187934875\n",
    "# metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde39a1f",
   "metadata": {},
   "source": [
    "We now make a class for every 10 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543285f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'[0 0]': np.int64(0), '[0 1]': np.int64(0), '[0 2]': np.int64(0), '[0 3]': np.int64(0), '[0 4]': np.int64(0), '[0 5]': np.int64(0), '[0 6]': np.int64(0), '[0 7]': np.int64(0), '[0 8]': np.int64(0), '[0 9]': np.int64(0), '[ 0 10]': np.int64(1), '[ 0 11]': np.int64(1), '[ 0 12]': np.int64(1), '[ 0 13]': np.int64(1), '[ 0 14]': np.int64(1), '[ 0 15]': np.int64(1), '[ 0 16]': np.int64(1), '[ 0 17]': np.int64(1), '[ 0 18]': np.int64(1), '[ 0 19]': np.int64(1), '[ 0 20]': np.int64(2), '[ 0 21]': np.int64(2), '[ 0 22]': np.int64(2), '[ 0 23]': np.int64(2), '[ 0 24]': np.int64(2), '[ 0 25]': np.int64(2), '[ 0 26]': np.int64(2), '[ 0 27]': np.int64(2), '[ 0 28]': np.int64(2), '[ 0 29]': np.int64(2), '[ 0 30]': np.int64(3), '[ 0 31]': np.int64(3), '[ 0 32]': np.int64(3), '[ 0 33]': np.int64(3), '[ 0 34]': np.int64(3), '[ 0 35]': np.int64(3), '[ 0 36]': np.int64(3), '[ 0 37]': np.int64(3), '[ 0 38]': np.int64(3), '[ 0 39]': np.int64(3), '[ 0 40]': np.int64(4), '[ 0 41]': np.int64(4), '[ 0 42]': np.int64(4), '[ 0 43]': np.int64(4), '[ 0 44]': np.int64(4), '[ 0 45]': np.int64(4), '[ 0 46]': np.int64(4), '[ 0 47]': np.int64(4), '[ 0 48]': np.int64(4), '[ 0 49]': np.int64(4), '[ 0 50]': np.int64(5), '[ 0 51]': np.int64(5), '[ 0 52]': np.int64(5), '[ 0 53]': np.int64(5), '[ 0 54]': np.int64(5), '[ 0 55]': np.int64(5), '[ 0 56]': np.int64(5), '[ 0 57]': np.int64(5), '[ 0 58]': np.int64(5), '[ 0 59]': np.int64(5), '[1 0]': np.int64(6), '[1 1]': np.int64(6), '[1 2]': np.int64(6), '[1 3]': np.int64(6), '[1 4]': np.int64(6), '[1 5]': np.int64(6), '[1 6]': np.int64(6), '[1 7]': np.int64(6), '[1 8]': np.int64(6), '[1 9]': np.int64(6), '[ 1 10]': np.int64(7), '[ 1 11]': np.int64(7), '[ 1 12]': np.int64(7), '[ 1 13]': np.int64(7), '[ 1 14]': np.int64(7), '[ 1 15]': np.int64(7), '[ 1 16]': np.int64(7), '[ 1 17]': np.int64(7), '[ 1 18]': np.int64(7), '[ 1 19]': np.int64(7), '[ 1 20]': np.int64(8), '[ 1 21]': np.int64(8), '[ 1 22]': np.int64(8), '[ 1 23]': np.int64(8), '[ 1 24]': np.int64(8), '[ 1 25]': np.int64(8), '[ 1 26]': np.int64(8), '[ 1 27]': np.int64(8), '[ 1 28]': np.int64(8), '[ 1 29]': np.int64(8), '[ 1 30]': np.int64(9), '[ 1 31]': np.int64(9), '[ 1 32]': np.int64(9), '[ 1 33]': np.int64(9), '[ 1 34]': np.int64(9), '[ 1 35]': np.int64(9), '[ 1 36]': np.int64(9), '[ 1 37]': np.int64(9), '[ 1 38]': np.int64(9), '[ 1 39]': np.int64(9), '[ 1 40]': np.int64(10), '[ 1 41]': np.int64(10), '[ 1 42]': np.int64(10), '[ 1 43]': np.int64(10), '[ 1 44]': np.int64(10), '[ 1 45]': np.int64(10), '[ 1 46]': np.int64(10), '[ 1 47]': np.int64(10), '[ 1 48]': np.int64(10), '[ 1 49]': np.int64(10), '[ 1 50]': np.int64(11), '[ 1 51]': np.int64(11), '[ 1 52]': np.int64(11), '[ 1 53]': np.int64(11), '[ 1 54]': np.int64(11), '[ 1 55]': np.int64(11), '[ 1 56]': np.int64(11), '[ 1 57]': np.int64(11), '[ 1 58]': np.int64(11), '[ 1 59]': np.int64(11), '[2 0]': np.int64(12), '[2 1]': np.int64(12), '[2 2]': np.int64(12), '[2 3]': np.int64(12), '[2 4]': np.int64(12), '[2 5]': np.int64(12), '[2 6]': np.int64(12), '[2 7]': np.int64(12), '[2 8]': np.int64(12), '[2 9]': np.int64(12), '[ 2 10]': np.int64(13), '[ 2 11]': np.int64(13), '[ 2 12]': np.int64(13), '[ 2 13]': np.int64(13), '[ 2 14]': np.int64(13), '[ 2 15]': np.int64(13), '[ 2 16]': np.int64(13), '[ 2 17]': np.int64(13), '[ 2 18]': np.int64(13), '[ 2 19]': np.int64(13), '[ 2 20]': np.int64(14), '[ 2 21]': np.int64(14), '[ 2 22]': np.int64(14), '[ 2 23]': np.int64(14), '[ 2 24]': np.int64(14), '[ 2 25]': np.int64(14), '[ 2 26]': np.int64(14), '[ 2 27]': np.int64(14), '[ 2 28]': np.int64(14), '[ 2 29]': np.int64(14), '[ 2 30]': np.int64(15), '[ 2 31]': np.int64(15), '[ 2 32]': np.int64(15), '[ 2 33]': np.int64(15), '[ 2 34]': np.int64(15), '[ 2 35]': np.int64(15), '[ 2 36]': np.int64(15), '[ 2 37]': np.int64(15), '[ 2 38]': np.int64(15), '[ 2 39]': np.int64(15), '[ 2 40]': np.int64(16), '[ 2 41]': np.int64(16), '[ 2 42]': np.int64(16), '[ 2 43]': np.int64(16), '[ 2 44]': np.int64(16), '[ 2 45]': np.int64(16), '[ 2 46]': np.int64(16), '[ 2 47]': np.int64(16), '[ 2 48]': np.int64(16), '[ 2 49]': np.int64(16), '[ 2 50]': np.int64(17), '[ 2 51]': np.int64(17), '[ 2 52]': np.int64(17), '[ 2 53]': np.int64(17), '[ 2 54]': np.int64(17), '[ 2 55]': np.int64(17), '[ 2 56]': np.int64(17), '[ 2 57]': np.int64(17), '[ 2 58]': np.int64(17), '[ 2 59]': np.int64(17), '[3 0]': np.int64(18), '[3 1]': np.int64(18), '[3 2]': np.int64(18), '[3 3]': np.int64(18), '[3 4]': np.int64(18), '[3 5]': np.int64(18), '[3 6]': np.int64(18), '[3 7]': np.int64(18), '[3 8]': np.int64(18), '[3 9]': np.int64(18), '[ 3 10]': np.int64(19), '[ 3 11]': np.int64(19), '[ 3 12]': np.int64(19), '[ 3 13]': np.int64(19), '[ 3 14]': np.int64(19), '[ 3 15]': np.int64(19), '[ 3 16]': np.int64(19), '[ 3 17]': np.int64(19), '[ 3 18]': np.int64(19), '[ 3 19]': np.int64(19), '[ 3 20]': np.int64(20), '[ 3 21]': np.int64(20), '[ 3 22]': np.int64(20), '[ 3 23]': np.int64(20), '[ 3 24]': np.int64(20), '[ 3 25]': np.int64(20), '[ 3 26]': np.int64(20), '[ 3 27]': np.int64(20), '[ 3 28]': np.int64(20), '[ 3 29]': np.int64(20), '[ 3 30]': np.int64(21), '[ 3 31]': np.int64(21), '[ 3 32]': np.int64(21), '[ 3 33]': np.int64(21), '[ 3 34]': np.int64(21), '[ 3 35]': np.int64(21), '[ 3 36]': np.int64(21), '[ 3 37]': np.int64(21), '[ 3 38]': np.int64(21), '[ 3 39]': np.int64(21), '[ 3 40]': np.int64(22), '[ 3 41]': np.int64(22), '[ 3 42]': np.int64(22), '[ 3 43]': np.int64(22), '[ 3 44]': np.int64(22), '[ 3 45]': np.int64(22), '[ 3 46]': np.int64(22), '[ 3 47]': np.int64(22), '[ 3 48]': np.int64(22), '[ 3 49]': np.int64(22), '[ 3 50]': np.int64(23), '[ 3 51]': np.int64(23), '[ 3 52]': np.int64(23), '[ 3 53]': np.int64(23), '[ 3 54]': np.int64(23), '[ 3 55]': np.int64(23), '[ 3 56]': np.int64(23), '[ 3 57]': np.int64(23), '[ 3 58]': np.int64(23), '[ 3 59]': np.int64(23), '[4 0]': np.int64(24), '[4 1]': np.int64(24), '[4 2]': np.int64(24), '[4 3]': np.int64(24), '[4 4]': np.int64(24), '[4 5]': np.int64(24), '[4 6]': np.int64(24), '[4 7]': np.int64(24), '[4 8]': np.int64(24), '[4 9]': np.int64(24), '[ 4 10]': np.int64(25), '[ 4 11]': np.int64(25), '[ 4 12]': np.int64(25), '[ 4 13]': np.int64(25), '[ 4 14]': np.int64(25), '[ 4 15]': np.int64(25), '[ 4 16]': np.int64(25), '[ 4 17]': np.int64(25), '[ 4 18]': np.int64(25), '[ 4 19]': np.int64(25), '[ 4 20]': np.int64(26), '[ 4 21]': np.int64(26), '[ 4 22]': np.int64(26), '[ 4 23]': np.int64(26), '[ 4 24]': np.int64(26), '[ 4 25]': np.int64(26), '[ 4 26]': np.int64(26), '[ 4 27]': np.int64(26), '[ 4 28]': np.int64(26), '[ 4 29]': np.int64(26), '[ 4 30]': np.int64(27), '[ 4 31]': np.int64(27), '[ 4 32]': np.int64(27), '[ 4 33]': np.int64(27), '[ 4 34]': np.int64(27), '[ 4 35]': np.int64(27), '[ 4 36]': np.int64(27), '[ 4 37]': np.int64(27), '[ 4 38]': np.int64(27), '[ 4 39]': np.int64(27), '[ 4 40]': np.int64(28), '[ 4 41]': np.int64(28), '[ 4 42]': np.int64(28), '[ 4 43]': np.int64(28), '[ 4 44]': np.int64(28), '[ 4 45]': np.int64(28), '[ 4 46]': np.int64(28), '[ 4 47]': np.int64(28), '[ 4 48]': np.int64(28), '[ 4 49]': np.int64(28), '[ 4 50]': np.int64(29), '[ 4 51]': np.int64(29), '[ 4 52]': np.int64(29), '[ 4 53]': np.int64(29), '[ 4 54]': np.int64(29), '[ 4 55]': np.int64(29), '[ 4 56]': np.int64(29), '[ 4 57]': np.int64(29), '[ 4 58]': np.int64(29), '[ 4 59]': np.int64(29), '[5 0]': np.int64(30), '[5 1]': np.int64(30), '[5 2]': np.int64(30), '[5 3]': np.int64(30), '[5 4]': np.int64(30), '[5 5]': np.int64(30), '[5 6]': np.int64(30), '[5 7]': np.int64(30), '[5 8]': np.int64(30), '[5 9]': np.int64(30), '[ 5 10]': np.int64(31), '[ 5 11]': np.int64(31), '[ 5 12]': np.int64(31), '[ 5 13]': np.int64(31), '[ 5 14]': np.int64(31), '[ 5 15]': np.int64(31), '[ 5 16]': np.int64(31), '[ 5 17]': np.int64(31), '[ 5 18]': np.int64(31), '[ 5 19]': np.int64(31), '[ 5 20]': np.int64(32), '[ 5 21]': np.int64(32), '[ 5 22]': np.int64(32), '[ 5 23]': np.int64(32), '[ 5 24]': np.int64(32), '[ 5 25]': np.int64(32), '[ 5 26]': np.int64(32), '[ 5 27]': np.int64(32), '[ 5 28]': np.int64(32), '[ 5 29]': np.int64(32), '[ 5 30]': np.int64(33), '[ 5 31]': np.int64(33), '[ 5 32]': np.int64(33), '[ 5 33]': np.int64(33), '[ 5 34]': np.int64(33), '[ 5 35]': np.int64(33), '[ 5 36]': np.int64(33), '[ 5 37]': np.int64(33), '[ 5 38]': np.int64(33), '[ 5 39]': np.int64(33), '[ 5 40]': np.int64(34), '[ 5 41]': np.int64(34), '[ 5 42]': np.int64(34), '[ 5 43]': np.int64(34), '[ 5 44]': np.int64(34), '[ 5 45]': np.int64(34), '[ 5 46]': np.int64(34), '[ 5 47]': np.int64(34), '[ 5 48]': np.int64(34), '[ 5 49]': np.int64(34), '[ 5 50]': np.int64(35), '[ 5 51]': np.int64(35), '[ 5 52]': np.int64(35), '[ 5 53]': np.int64(35), '[ 5 54]': np.int64(35), '[ 5 55]': np.int64(35), '[ 5 56]': np.int64(35), '[ 5 57]': np.int64(35), '[ 5 58]': np.int64(35), '[ 5 59]': np.int64(35), '[6 0]': np.int64(36), '[6 1]': np.int64(36), '[6 2]': np.int64(36), '[6 3]': np.int64(36), '[6 4]': np.int64(36), '[6 5]': np.int64(36), '[6 6]': np.int64(36), '[6 7]': np.int64(36), '[6 8]': np.int64(36), '[6 9]': np.int64(36), '[ 6 10]': np.int64(37), '[ 6 11]': np.int64(37), '[ 6 12]': np.int64(37), '[ 6 13]': np.int64(37), '[ 6 14]': np.int64(37), '[ 6 15]': np.int64(37), '[ 6 16]': np.int64(37), '[ 6 17]': np.int64(37), '[ 6 18]': np.int64(37), '[ 6 19]': np.int64(37), '[ 6 20]': np.int64(38), '[ 6 21]': np.int64(38), '[ 6 22]': np.int64(38), '[ 6 23]': np.int64(38), '[ 6 24]': np.int64(38), '[ 6 25]': np.int64(38), '[ 6 26]': np.int64(38), '[ 6 27]': np.int64(38), '[ 6 28]': np.int64(38), '[ 6 29]': np.int64(38), '[ 6 30]': np.int64(39), '[ 6 31]': np.int64(39), '[ 6 32]': np.int64(39), '[ 6 33]': np.int64(39), '[ 6 34]': np.int64(39), '[ 6 35]': np.int64(39), '[ 6 36]': np.int64(39), '[ 6 37]': np.int64(39), '[ 6 38]': np.int64(39), '[ 6 39]': np.int64(39), '[ 6 40]': np.int64(40), '[ 6 41]': np.int64(40), '[ 6 42]': np.int64(40), '[ 6 43]': np.int64(40), '[ 6 44]': np.int64(40), '[ 6 45]': np.int64(40), '[ 6 46]': np.int64(40), '[ 6 47]': np.int64(40), '[ 6 48]': np.int64(40), '[ 6 49]': np.int64(40), '[ 6 50]': np.int64(41), '[ 6 51]': np.int64(41), '[ 6 52]': np.int64(41), '[ 6 53]': np.int64(41), '[ 6 54]': np.int64(41), '[ 6 55]': np.int64(41), '[ 6 56]': np.int64(41), '[ 6 57]': np.int64(41), '[ 6 58]': np.int64(41), '[ 6 59]': np.int64(41), '[7 0]': np.int64(42), '[7 1]': np.int64(42), '[7 2]': np.int64(42), '[7 3]': np.int64(42), '[7 4]': np.int64(42), '[7 5]': np.int64(42), '[7 6]': np.int64(42), '[7 7]': np.int64(42), '[7 8]': np.int64(42), '[7 9]': np.int64(42), '[ 7 10]': np.int64(43), '[ 7 11]': np.int64(43), '[ 7 12]': np.int64(43), '[ 7 13]': np.int64(43), '[ 7 14]': np.int64(43), '[ 7 15]': np.int64(43), '[ 7 16]': np.int64(43), '[ 7 17]': np.int64(43), '[ 7 18]': np.int64(43), '[ 7 19]': np.int64(43), '[ 7 20]': np.int64(44), '[ 7 21]': np.int64(44), '[ 7 22]': np.int64(44), '[ 7 23]': np.int64(44), '[ 7 24]': np.int64(44), '[ 7 25]': np.int64(44), '[ 7 26]': np.int64(44), '[ 7 27]': np.int64(44), '[ 7 28]': np.int64(44), '[ 7 29]': np.int64(44), '[ 7 30]': np.int64(45), '[ 7 31]': np.int64(45), '[ 7 32]': np.int64(45), '[ 7 33]': np.int64(45), '[ 7 34]': np.int64(45), '[ 7 35]': np.int64(45), '[ 7 36]': np.int64(45), '[ 7 37]': np.int64(45), '[ 7 38]': np.int64(45), '[ 7 39]': np.int64(45), '[ 7 40]': np.int64(46), '[ 7 41]': np.int64(46), '[ 7 42]': np.int64(46), '[ 7 43]': np.int64(46), '[ 7 44]': np.int64(46), '[ 7 45]': np.int64(46), '[ 7 46]': np.int64(46), '[ 7 47]': np.int64(46), '[ 7 48]': np.int64(46), '[ 7 49]': np.int64(46), '[ 7 50]': np.int64(47), '[ 7 51]': np.int64(47), '[ 7 52]': np.int64(47), '[ 7 53]': np.int64(47), '[ 7 54]': np.int64(47), '[ 7 55]': np.int64(47), '[ 7 56]': np.int64(47), '[ 7 57]': np.int64(47), '[ 7 58]': np.int64(47), '[ 7 59]': np.int64(47), '[8 0]': np.int64(48), '[8 1]': np.int64(48), '[8 2]': np.int64(48), '[8 3]': np.int64(48), '[8 4]': np.int64(48), '[8 5]': np.int64(48), '[8 6]': np.int64(48), '[8 7]': np.int64(48), '[8 8]': np.int64(48), '[8 9]': np.int64(48), '[ 8 10]': np.int64(49), '[ 8 11]': np.int64(49), '[ 8 12]': np.int64(49), '[ 8 13]': np.int64(49), '[ 8 14]': np.int64(49), '[ 8 15]': np.int64(49), '[ 8 16]': np.int64(49), '[ 8 17]': np.int64(49), '[ 8 18]': np.int64(49), '[ 8 19]': np.int64(49), '[ 8 20]': np.int64(50), '[ 8 21]': np.int64(50), '[ 8 22]': np.int64(50), '[ 8 23]': np.int64(50), '[ 8 24]': np.int64(50), '[ 8 25]': np.int64(50), '[ 8 26]': np.int64(50), '[ 8 27]': np.int64(50), '[ 8 28]': np.int64(50), '[ 8 29]': np.int64(50), '[ 8 30]': np.int64(51), '[ 8 31]': np.int64(51), '[ 8 32]': np.int64(51), '[ 8 33]': np.int64(51), '[ 8 34]': np.int64(51), '[ 8 35]': np.int64(51), '[ 8 36]': np.int64(51), '[ 8 37]': np.int64(51), '[ 8 38]': np.int64(51), '[ 8 39]': np.int64(51), '[ 8 40]': np.int64(52), '[ 8 41]': np.int64(52), '[ 8 42]': np.int64(52), '[ 8 43]': np.int64(52), '[ 8 44]': np.int64(52), '[ 8 45]': np.int64(52), '[ 8 46]': np.int64(52), '[ 8 47]': np.int64(52), '[ 8 48]': np.int64(52), '[ 8 49]': np.int64(52), '[ 8 50]': np.int64(53), '[ 8 51]': np.int64(53), '[ 8 52]': np.int64(53), '[ 8 53]': np.int64(53), '[ 8 54]': np.int64(53), '[ 8 55]': np.int64(53), '[ 8 56]': np.int64(53), '[ 8 57]': np.int64(53), '[ 8 58]': np.int64(53), '[ 8 59]': np.int64(53), '[9 0]': np.int64(54), '[9 1]': np.int64(54), '[9 2]': np.int64(54), '[9 3]': np.int64(54), '[9 4]': np.int64(54), '[9 5]': np.int64(54), '[9 6]': np.int64(54), '[9 7]': np.int64(54), '[9 8]': np.int64(54), '[9 9]': np.int64(54), '[ 9 10]': np.int64(55), '[ 9 11]': np.int64(55), '[ 9 12]': np.int64(55), '[ 9 13]': np.int64(55), '[ 9 14]': np.int64(55), '[ 9 15]': np.int64(55), '[ 9 16]': np.int64(55), '[ 9 17]': np.int64(55), '[ 9 18]': np.int64(55), '[ 9 19]': np.int64(55), '[ 9 20]': np.int64(56), '[ 9 21]': np.int64(56), '[ 9 22]': np.int64(56), '[ 9 23]': np.int64(56), '[ 9 24]': np.int64(56), '[ 9 25]': np.int64(56), '[ 9 26]': np.int64(56), '[ 9 27]': np.int64(56), '[ 9 28]': np.int64(56), '[ 9 29]': np.int64(56), '[ 9 30]': np.int64(57), '[ 9 31]': np.int64(57), '[ 9 32]': np.int64(57), '[ 9 33]': np.int64(57), '[ 9 34]': np.int64(57), '[ 9 35]': np.int64(57), '[ 9 36]': np.int64(57), '[ 9 37]': np.int64(57), '[ 9 38]': np.int64(57), '[ 9 39]': np.int64(57), '[ 9 40]': np.int64(58), '[ 9 41]': np.int64(58), '[ 9 42]': np.int64(58), '[ 9 43]': np.int64(58), '[ 9 44]': np.int64(58), '[ 9 45]': np.int64(58), '[ 9 46]': np.int64(58), '[ 9 47]': np.int64(58), '[ 9 48]': np.int64(58), '[ 9 49]': np.int64(58), '[ 9 50]': np.int64(59), '[ 9 51]': np.int64(59), '[ 9 52]': np.int64(59), '[ 9 53]': np.int64(59), '[ 9 54]': np.int64(59), '[ 9 55]': np.int64(59), '[ 9 56]': np.int64(59), '[ 9 57]': np.int64(59), '[ 9 58]': np.int64(59), '[ 9 59]': np.int64(59), '[10  0]': np.int64(60), '[10  1]': np.int64(60), '[10  2]': np.int64(60), '[10  3]': np.int64(60), '[10  4]': np.int64(60), '[10  5]': np.int64(60), '[10  6]': np.int64(60), '[10  7]': np.int64(60), '[10  8]': np.int64(60), '[10  9]': np.int64(60), '[10 10]': np.int64(61), '[10 11]': np.int64(61), '[10 12]': np.int64(61), '[10 13]': np.int64(61), '[10 14]': np.int64(61), '[10 15]': np.int64(61), '[10 16]': np.int64(61), '[10 17]': np.int64(61), '[10 18]': np.int64(61), '[10 19]': np.int64(61), '[10 20]': np.int64(62), '[10 21]': np.int64(62), '[10 22]': np.int64(62), '[10 23]': np.int64(62), '[10 24]': np.int64(62), '[10 25]': np.int64(62), '[10 26]': np.int64(62), '[10 27]': np.int64(62), '[10 28]': np.int64(62), '[10 29]': np.int64(62), '[10 30]': np.int64(63), '[10 31]': np.int64(63), '[10 32]': np.int64(63), '[10 33]': np.int64(63), '[10 34]': np.int64(63), '[10 35]': np.int64(63), '[10 36]': np.int64(63), '[10 37]': np.int64(63), '[10 38]': np.int64(63), '[10 39]': np.int64(63), '[10 40]': np.int64(64), '[10 41]': np.int64(64), '[10 42]': np.int64(64), '[10 43]': np.int64(64), '[10 44]': np.int64(64), '[10 45]': np.int64(64), '[10 46]': np.int64(64), '[10 47]': np.int64(64), '[10 48]': np.int64(64), '[10 49]': np.int64(64), '[10 50]': np.int64(65), '[10 51]': np.int64(65), '[10 52]': np.int64(65), '[10 53]': np.int64(65), '[10 54]': np.int64(65), '[10 55]': np.int64(65), '[10 56]': np.int64(65), '[10 57]': np.int64(65), '[10 58]': np.int64(65), '[10 59]': np.int64(65), '[11  0]': np.int64(66), '[11  1]': np.int64(66), '[11  2]': np.int64(66), '[11  3]': np.int64(66), '[11  4]': np.int64(66), '[11  5]': np.int64(66), '[11  6]': np.int64(66), '[11  7]': np.int64(66), '[11  8]': np.int64(66), '[11  9]': np.int64(66), '[11 10]': np.int64(67), '[11 11]': np.int64(67), '[11 12]': np.int64(67), '[11 13]': np.int64(67), '[11 14]': np.int64(67), '[11 15]': np.int64(67), '[11 16]': np.int64(67), '[11 17]': np.int64(67), '[11 18]': np.int64(67), '[11 19]': np.int64(67), '[11 20]': np.int64(68), '[11 21]': np.int64(68), '[11 22]': np.int64(68), '[11 23]': np.int64(68), '[11 24]': np.int64(68), '[11 25]': np.int64(68), '[11 26]': np.int64(68), '[11 27]': np.int64(68), '[11 28]': np.int64(68), '[11 29]': np.int64(68), '[11 30]': np.int64(69), '[11 31]': np.int64(69), '[11 32]': np.int64(69), '[11 33]': np.int64(69), '[11 34]': np.int64(69), '[11 35]': np.int64(69), '[11 36]': np.int64(69), '[11 37]': np.int64(69), '[11 38]': np.int64(69), '[11 39]': np.int64(69), '[11 40]': np.int64(70), '[11 41]': np.int64(70), '[11 42]': np.int64(70), '[11 43]': np.int64(70), '[11 44]': np.int64(70), '[11 45]': np.int64(70), '[11 46]': np.int64(70), '[11 47]': np.int64(70), '[11 48]': np.int64(70), '[11 49]': np.int64(70), '[11 50]': np.int64(71), '[11 51]': np.int64(71), '[11 52]': np.int64(71), '[11 53]': np.int64(71), '[11 54]': np.int64(71), '[11 55]': np.int64(71), '[11 56]': np.int64(71), '[11 57]': np.int64(71), '[11 58]': np.int64(71), '[11 59]': np.int64(71)}\n"
     ]
    }
   ],
   "source": [
    "labels = np.load(labels_path)\n",
    "\n",
    "def get_cat_labels_10(labels):\n",
    "    new_labels = []\n",
    "    dct = {}\n",
    "    for label in labels:\n",
    "        old = label\n",
    "        label = label[0]* 6 + int((label[1])/10)\n",
    "        new_labels.append(label)\n",
    "        dct[str(old)] = label\n",
    "    print(dct)\n",
    "    return np.array(new_labels)\n",
    "labels = get_cat_labels_10(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "482e8cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test,y_train_full, y_test = train_test_split(\n",
    "    images, labels, test_size=0.1, random_state=35\n",
    ")\n",
    "X_train, X_valid,y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=1/9, random_state=35\n",
    ") # 1/9 x 0.9 = 0.1. train test split shuffles by default\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bce00e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_sense_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    y_pred_class = tf.argmax(y_pred, axis=1)\n",
    "    y_true_float = tf.cast(tf.squeeze(y_true), dtype=tf.float32)\n",
    "    y_pred_float = tf.cast(y_pred_class, dtype=tf.float32)\n",
    "    diff = tf.abs(y_true_float - y_pred_float)\n",
    "    cyclical_diff = tf.minimum(diff, 12.0 - diff)\n",
    "    print(cyclical_diff)\n",
    "    return tf.reduce_mean(cyclical_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3f836073",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pool = keras.layers.MaxPool2D(pool_size=2)\n",
    "lr_scheduler = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,          # halce the learning rate if no improvement\n",
    "    patience=2,          # Wait 2 epochs with no improvement before reducing\n",
    "    min_lr=1e-6          # Set a minimum learning rate at 1e-6\n",
    ")\n",
    "early_stopper = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,          # Wait 5 epochs for improvement before stopping\n",
    "    restore_best_weights=True  # Automatically restore the model weights from the best epoch\n",
    ")\n",
    "# avg_pool = keras.layers.AveragePooling2D(pool_size=2)\n",
    "model = keras.models.Sequential([\n",
    "    keras.Input(shape=(75, 75, 1)),\n",
    "    # Block 1\n",
    "    keras.layers.Conv2D(32, (3,3), activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPooling2D((2,2)), # Output shape: (37, 37, 32)\n",
    "\n",
    "    # Block 2\n",
    "    keras.layers.Conv2D(64, (3,3), activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(64, (3,3), activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPooling2D(2), # Output shape: (18, 18, 64)\n",
    "\n",
    "    # Block 3\n",
    "    keras.layers.Conv2D(128, (3,3), activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(128, (3,3), activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPooling2D(2), # Output shape: (9, 9, 128)\n",
    "\n",
    "    # Block 4\n",
    "    keras.layers.Conv2D(256, (3,3), activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPooling2D(2), # Output shape: (4, 4, 256)\n",
    "\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128, activation=\"leaky_relu\"),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(64, activation=\"leaky_relu\"),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(72, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "metrics=[common_sense_loss,\"Accuracy\"\n",
    "        #   tf.keras.metrics.Precision(), tf.keras.metrics.Recall()\n",
    "          ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e82a6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - Accuracy: 0.9309 - common_sense_loss: 0.0900 - loss: 0.2031 - val_Accuracy: 0.9156 - val_common_sense_loss: 0.1091 - val_loss: 0.2537 - learning_rate: 3.1250e-05\n",
      "Epoch 2/10\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - Accuracy: 0.9324 - common_sense_loss: 0.0492 - loss: 0.1923 - val_Accuracy: 0.9122 - val_common_sense_loss: 0.0735 - val_loss: 0.2550 - learning_rate: 3.1250e-05\n",
      "Epoch 3/10\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - Accuracy: 0.9317 - common_sense_loss: 0.0530 - loss: 0.1989 - val_Accuracy: 0.9100 - val_common_sense_loss: 0.0707 - val_loss: 0.2669 - learning_rate: 3.1250e-05\n",
      "Epoch 4/10\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - Accuracy: 0.9408 - common_sense_loss: 0.0096 - loss: 0.1797 - val_Accuracy: 0.9133 - val_common_sense_loss: 0.0768 - val_loss: 0.2498 - learning_rate: 1.5625e-05\n",
      "Epoch 5/10\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - Accuracy: 0.9401 - common_sense_loss: 0.0856 - loss: 0.1767 - val_Accuracy: 0.9122 - val_common_sense_loss: 0.0800 - val_loss: 0.2646 - learning_rate: 1.5625e-05\n",
      "Epoch 6/10\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - Accuracy: 0.9359 - common_sense_loss: 0.0411 - loss: 0.1909 - val_Accuracy: 0.9094 - val_common_sense_loss: 0.0658 - val_loss: 0.2576 - learning_rate: 1.5625e-05\n",
      "Epoch 7/10\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - Accuracy: 0.9388 - common_sense_loss: 0.0474 - loss: 0.1779 - val_Accuracy: 0.9128 - val_common_sense_loss: 0.0740 - val_loss: 0.2560 - learning_rate: 7.8125e-06\n",
      "Epoch 8/10\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - Accuracy: 0.9360 - common_sense_loss: 0.0549 - loss: 0.1770 - val_Accuracy: 0.9133 - val_common_sense_loss: 0.0521 - val_loss: 0.2532 - learning_rate: 7.8125e-06\n",
      "Epoch 9/10\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - Accuracy: 0.9433 - common_sense_loss: 0.0039 - loss: 0.1681 - val_Accuracy: 0.9128 - val_common_sense_loss: 0.0274 - val_loss: 0.2509 - learning_rate: 3.9063e-06\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Accuracy: 0.9194 - common_sense_loss: 0.1234 - loss: 0.2614\n",
      "Test accuracy: 0.9194444417953491\n",
      "2.20.0\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=10,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=[lr_scheduler, early_stopper]\n",
    "    )\n",
    "#evaluate the model on the test set\n",
    "test_loss,test_csl, test_acc = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', test_acc)\n",
    "#base:0.8420000076293945\n",
    "#leaky: 0.8525000214576721\n",
    "#leaky + L2regularization: 0.8472999930381775\n",
    "#leaky + batch normalization: 0.8978000283241272\n",
    "\n",
    "(print(tf.__version__))\n",
    "#0.9194444417953491\n",
    "# metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "23733489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'[0 0]': np.int64(0), '[0 1]': np.int64(1), '[0 2]': np.int64(2), '[0 3]': np.int64(3), '[0 4]': np.int64(4), '[0 5]': np.int64(5), '[0 6]': np.int64(6), '[0 7]': np.int64(7), '[0 8]': np.int64(8), '[0 9]': np.int64(9), '[ 0 10]': np.int64(10), '[ 0 11]': np.int64(11), '[ 0 12]': np.int64(12), '[ 0 13]': np.int64(13), '[ 0 14]': np.int64(14), '[ 0 15]': np.int64(15), '[ 0 16]': np.int64(16), '[ 0 17]': np.int64(17), '[ 0 18]': np.int64(18), '[ 0 19]': np.int64(19), '[ 0 20]': np.int64(20), '[ 0 21]': np.int64(21), '[ 0 22]': np.int64(22), '[ 0 23]': np.int64(23), '[ 0 24]': np.int64(24), '[ 0 25]': np.int64(25), '[ 0 26]': np.int64(26), '[ 0 27]': np.int64(27), '[ 0 28]': np.int64(28), '[ 0 29]': np.int64(29), '[ 0 30]': np.int64(30), '[ 0 31]': np.int64(31), '[ 0 32]': np.int64(32), '[ 0 33]': np.int64(33), '[ 0 34]': np.int64(34), '[ 0 35]': np.int64(35), '[ 0 36]': np.int64(36), '[ 0 37]': np.int64(37), '[ 0 38]': np.int64(38), '[ 0 39]': np.int64(39), '[ 0 40]': np.int64(40), '[ 0 41]': np.int64(41), '[ 0 42]': np.int64(42), '[ 0 43]': np.int64(43), '[ 0 44]': np.int64(44), '[ 0 45]': np.int64(45), '[ 0 46]': np.int64(46), '[ 0 47]': np.int64(47), '[ 0 48]': np.int64(48), '[ 0 49]': np.int64(49), '[ 0 50]': np.int64(50), '[ 0 51]': np.int64(51), '[ 0 52]': np.int64(52), '[ 0 53]': np.int64(53), '[ 0 54]': np.int64(54), '[ 0 55]': np.int64(55), '[ 0 56]': np.int64(56), '[ 0 57]': np.int64(57), '[ 0 58]': np.int64(58), '[ 0 59]': np.int64(59), '[1 0]': np.int64(60), '[1 1]': np.int64(61), '[1 2]': np.int64(62), '[1 3]': np.int64(63), '[1 4]': np.int64(64), '[1 5]': np.int64(65), '[1 6]': np.int64(66), '[1 7]': np.int64(67), '[1 8]': np.int64(68), '[1 9]': np.int64(69), '[ 1 10]': np.int64(70), '[ 1 11]': np.int64(71), '[ 1 12]': np.int64(72), '[ 1 13]': np.int64(73), '[ 1 14]': np.int64(74), '[ 1 15]': np.int64(75), '[ 1 16]': np.int64(76), '[ 1 17]': np.int64(77), '[ 1 18]': np.int64(78), '[ 1 19]': np.int64(79), '[ 1 20]': np.int64(80), '[ 1 21]': np.int64(81), '[ 1 22]': np.int64(82), '[ 1 23]': np.int64(83), '[ 1 24]': np.int64(84), '[ 1 25]': np.int64(85), '[ 1 26]': np.int64(86), '[ 1 27]': np.int64(87), '[ 1 28]': np.int64(88), '[ 1 29]': np.int64(89), '[ 1 30]': np.int64(90), '[ 1 31]': np.int64(91), '[ 1 32]': np.int64(92), '[ 1 33]': np.int64(93), '[ 1 34]': np.int64(94), '[ 1 35]': np.int64(95), '[ 1 36]': np.int64(96), '[ 1 37]': np.int64(97), '[ 1 38]': np.int64(98), '[ 1 39]': np.int64(99), '[ 1 40]': np.int64(100), '[ 1 41]': np.int64(101), '[ 1 42]': np.int64(102), '[ 1 43]': np.int64(103), '[ 1 44]': np.int64(104), '[ 1 45]': np.int64(105), '[ 1 46]': np.int64(106), '[ 1 47]': np.int64(107), '[ 1 48]': np.int64(108), '[ 1 49]': np.int64(109), '[ 1 50]': np.int64(110), '[ 1 51]': np.int64(111), '[ 1 52]': np.int64(112), '[ 1 53]': np.int64(113), '[ 1 54]': np.int64(114), '[ 1 55]': np.int64(115), '[ 1 56]': np.int64(116), '[ 1 57]': np.int64(117), '[ 1 58]': np.int64(118), '[ 1 59]': np.int64(119), '[2 0]': np.int64(120), '[2 1]': np.int64(121), '[2 2]': np.int64(122), '[2 3]': np.int64(123), '[2 4]': np.int64(124), '[2 5]': np.int64(125), '[2 6]': np.int64(126), '[2 7]': np.int64(127), '[2 8]': np.int64(128), '[2 9]': np.int64(129), '[ 2 10]': np.int64(130), '[ 2 11]': np.int64(131), '[ 2 12]': np.int64(132), '[ 2 13]': np.int64(133), '[ 2 14]': np.int64(134), '[ 2 15]': np.int64(135), '[ 2 16]': np.int64(136), '[ 2 17]': np.int64(137), '[ 2 18]': np.int64(138), '[ 2 19]': np.int64(139), '[ 2 20]': np.int64(140), '[ 2 21]': np.int64(141), '[ 2 22]': np.int64(142), '[ 2 23]': np.int64(143), '[ 2 24]': np.int64(144), '[ 2 25]': np.int64(145), '[ 2 26]': np.int64(146), '[ 2 27]': np.int64(147), '[ 2 28]': np.int64(148), '[ 2 29]': np.int64(149), '[ 2 30]': np.int64(150), '[ 2 31]': np.int64(151), '[ 2 32]': np.int64(152), '[ 2 33]': np.int64(153), '[ 2 34]': np.int64(154), '[ 2 35]': np.int64(155), '[ 2 36]': np.int64(156), '[ 2 37]': np.int64(157), '[ 2 38]': np.int64(158), '[ 2 39]': np.int64(159), '[ 2 40]': np.int64(160), '[ 2 41]': np.int64(161), '[ 2 42]': np.int64(162), '[ 2 43]': np.int64(163), '[ 2 44]': np.int64(164), '[ 2 45]': np.int64(165), '[ 2 46]': np.int64(166), '[ 2 47]': np.int64(167), '[ 2 48]': np.int64(168), '[ 2 49]': np.int64(169), '[ 2 50]': np.int64(170), '[ 2 51]': np.int64(171), '[ 2 52]': np.int64(172), '[ 2 53]': np.int64(173), '[ 2 54]': np.int64(174), '[ 2 55]': np.int64(175), '[ 2 56]': np.int64(176), '[ 2 57]': np.int64(177), '[ 2 58]': np.int64(178), '[ 2 59]': np.int64(179), '[3 0]': np.int64(180), '[3 1]': np.int64(181), '[3 2]': np.int64(182), '[3 3]': np.int64(183), '[3 4]': np.int64(184), '[3 5]': np.int64(185), '[3 6]': np.int64(186), '[3 7]': np.int64(187), '[3 8]': np.int64(188), '[3 9]': np.int64(189), '[ 3 10]': np.int64(190), '[ 3 11]': np.int64(191), '[ 3 12]': np.int64(192), '[ 3 13]': np.int64(193), '[ 3 14]': np.int64(194), '[ 3 15]': np.int64(195), '[ 3 16]': np.int64(196), '[ 3 17]': np.int64(197), '[ 3 18]': np.int64(198), '[ 3 19]': np.int64(199), '[ 3 20]': np.int64(200), '[ 3 21]': np.int64(201), '[ 3 22]': np.int64(202), '[ 3 23]': np.int64(203), '[ 3 24]': np.int64(204), '[ 3 25]': np.int64(205), '[ 3 26]': np.int64(206), '[ 3 27]': np.int64(207), '[ 3 28]': np.int64(208), '[ 3 29]': np.int64(209), '[ 3 30]': np.int64(210), '[ 3 31]': np.int64(211), '[ 3 32]': np.int64(212), '[ 3 33]': np.int64(213), '[ 3 34]': np.int64(214), '[ 3 35]': np.int64(215), '[ 3 36]': np.int64(216), '[ 3 37]': np.int64(217), '[ 3 38]': np.int64(218), '[ 3 39]': np.int64(219), '[ 3 40]': np.int64(220), '[ 3 41]': np.int64(221), '[ 3 42]': np.int64(222), '[ 3 43]': np.int64(223), '[ 3 44]': np.int64(224), '[ 3 45]': np.int64(225), '[ 3 46]': np.int64(226), '[ 3 47]': np.int64(227), '[ 3 48]': np.int64(228), '[ 3 49]': np.int64(229), '[ 3 50]': np.int64(230), '[ 3 51]': np.int64(231), '[ 3 52]': np.int64(232), '[ 3 53]': np.int64(233), '[ 3 54]': np.int64(234), '[ 3 55]': np.int64(235), '[ 3 56]': np.int64(236), '[ 3 57]': np.int64(237), '[ 3 58]': np.int64(238), '[ 3 59]': np.int64(239), '[4 0]': np.int64(240), '[4 1]': np.int64(241), '[4 2]': np.int64(242), '[4 3]': np.int64(243), '[4 4]': np.int64(244), '[4 5]': np.int64(245), '[4 6]': np.int64(246), '[4 7]': np.int64(247), '[4 8]': np.int64(248), '[4 9]': np.int64(249), '[ 4 10]': np.int64(250), '[ 4 11]': np.int64(251), '[ 4 12]': np.int64(252), '[ 4 13]': np.int64(253), '[ 4 14]': np.int64(254), '[ 4 15]': np.int64(255), '[ 4 16]': np.int64(256), '[ 4 17]': np.int64(257), '[ 4 18]': np.int64(258), '[ 4 19]': np.int64(259), '[ 4 20]': np.int64(260), '[ 4 21]': np.int64(261), '[ 4 22]': np.int64(262), '[ 4 23]': np.int64(263), '[ 4 24]': np.int64(264), '[ 4 25]': np.int64(265), '[ 4 26]': np.int64(266), '[ 4 27]': np.int64(267), '[ 4 28]': np.int64(268), '[ 4 29]': np.int64(269), '[ 4 30]': np.int64(270), '[ 4 31]': np.int64(271), '[ 4 32]': np.int64(272), '[ 4 33]': np.int64(273), '[ 4 34]': np.int64(274), '[ 4 35]': np.int64(275), '[ 4 36]': np.int64(276), '[ 4 37]': np.int64(277), '[ 4 38]': np.int64(278), '[ 4 39]': np.int64(279), '[ 4 40]': np.int64(280), '[ 4 41]': np.int64(281), '[ 4 42]': np.int64(282), '[ 4 43]': np.int64(283), '[ 4 44]': np.int64(284), '[ 4 45]': np.int64(285), '[ 4 46]': np.int64(286), '[ 4 47]': np.int64(287), '[ 4 48]': np.int64(288), '[ 4 49]': np.int64(289), '[ 4 50]': np.int64(290), '[ 4 51]': np.int64(291), '[ 4 52]': np.int64(292), '[ 4 53]': np.int64(293), '[ 4 54]': np.int64(294), '[ 4 55]': np.int64(295), '[ 4 56]': np.int64(296), '[ 4 57]': np.int64(297), '[ 4 58]': np.int64(298), '[ 4 59]': np.int64(299), '[5 0]': np.int64(300), '[5 1]': np.int64(301), '[5 2]': np.int64(302), '[5 3]': np.int64(303), '[5 4]': np.int64(304), '[5 5]': np.int64(305), '[5 6]': np.int64(306), '[5 7]': np.int64(307), '[5 8]': np.int64(308), '[5 9]': np.int64(309), '[ 5 10]': np.int64(310), '[ 5 11]': np.int64(311), '[ 5 12]': np.int64(312), '[ 5 13]': np.int64(313), '[ 5 14]': np.int64(314), '[ 5 15]': np.int64(315), '[ 5 16]': np.int64(316), '[ 5 17]': np.int64(317), '[ 5 18]': np.int64(318), '[ 5 19]': np.int64(319), '[ 5 20]': np.int64(320), '[ 5 21]': np.int64(321), '[ 5 22]': np.int64(322), '[ 5 23]': np.int64(323), '[ 5 24]': np.int64(324), '[ 5 25]': np.int64(325), '[ 5 26]': np.int64(326), '[ 5 27]': np.int64(327), '[ 5 28]': np.int64(328), '[ 5 29]': np.int64(329), '[ 5 30]': np.int64(330), '[ 5 31]': np.int64(331), '[ 5 32]': np.int64(332), '[ 5 33]': np.int64(333), '[ 5 34]': np.int64(334), '[ 5 35]': np.int64(335), '[ 5 36]': np.int64(336), '[ 5 37]': np.int64(337), '[ 5 38]': np.int64(338), '[ 5 39]': np.int64(339), '[ 5 40]': np.int64(340), '[ 5 41]': np.int64(341), '[ 5 42]': np.int64(342), '[ 5 43]': np.int64(343), '[ 5 44]': np.int64(344), '[ 5 45]': np.int64(345), '[ 5 46]': np.int64(346), '[ 5 47]': np.int64(347), '[ 5 48]': np.int64(348), '[ 5 49]': np.int64(349), '[ 5 50]': np.int64(350), '[ 5 51]': np.int64(351), '[ 5 52]': np.int64(352), '[ 5 53]': np.int64(353), '[ 5 54]': np.int64(354), '[ 5 55]': np.int64(355), '[ 5 56]': np.int64(356), '[ 5 57]': np.int64(357), '[ 5 58]': np.int64(358), '[ 5 59]': np.int64(359), '[6 0]': np.int64(360), '[6 1]': np.int64(361), '[6 2]': np.int64(362), '[6 3]': np.int64(363), '[6 4]': np.int64(364), '[6 5]': np.int64(365), '[6 6]': np.int64(366), '[6 7]': np.int64(367), '[6 8]': np.int64(368), '[6 9]': np.int64(369), '[ 6 10]': np.int64(370), '[ 6 11]': np.int64(371), '[ 6 12]': np.int64(372), '[ 6 13]': np.int64(373), '[ 6 14]': np.int64(374), '[ 6 15]': np.int64(375), '[ 6 16]': np.int64(376), '[ 6 17]': np.int64(377), '[ 6 18]': np.int64(378), '[ 6 19]': np.int64(379), '[ 6 20]': np.int64(380), '[ 6 21]': np.int64(381), '[ 6 22]': np.int64(382), '[ 6 23]': np.int64(383), '[ 6 24]': np.int64(384), '[ 6 25]': np.int64(385), '[ 6 26]': np.int64(386), '[ 6 27]': np.int64(387), '[ 6 28]': np.int64(388), '[ 6 29]': np.int64(389), '[ 6 30]': np.int64(390), '[ 6 31]': np.int64(391), '[ 6 32]': np.int64(392), '[ 6 33]': np.int64(393), '[ 6 34]': np.int64(394), '[ 6 35]': np.int64(395), '[ 6 36]': np.int64(396), '[ 6 37]': np.int64(397), '[ 6 38]': np.int64(398), '[ 6 39]': np.int64(399), '[ 6 40]': np.int64(400), '[ 6 41]': np.int64(401), '[ 6 42]': np.int64(402), '[ 6 43]': np.int64(403), '[ 6 44]': np.int64(404), '[ 6 45]': np.int64(405), '[ 6 46]': np.int64(406), '[ 6 47]': np.int64(407), '[ 6 48]': np.int64(408), '[ 6 49]': np.int64(409), '[ 6 50]': np.int64(410), '[ 6 51]': np.int64(411), '[ 6 52]': np.int64(412), '[ 6 53]': np.int64(413), '[ 6 54]': np.int64(414), '[ 6 55]': np.int64(415), '[ 6 56]': np.int64(416), '[ 6 57]': np.int64(417), '[ 6 58]': np.int64(418), '[ 6 59]': np.int64(419), '[7 0]': np.int64(420), '[7 1]': np.int64(421), '[7 2]': np.int64(422), '[7 3]': np.int64(423), '[7 4]': np.int64(424), '[7 5]': np.int64(425), '[7 6]': np.int64(426), '[7 7]': np.int64(427), '[7 8]': np.int64(428), '[7 9]': np.int64(429), '[ 7 10]': np.int64(430), '[ 7 11]': np.int64(431), '[ 7 12]': np.int64(432), '[ 7 13]': np.int64(433), '[ 7 14]': np.int64(434), '[ 7 15]': np.int64(435), '[ 7 16]': np.int64(436), '[ 7 17]': np.int64(437), '[ 7 18]': np.int64(438), '[ 7 19]': np.int64(439), '[ 7 20]': np.int64(440), '[ 7 21]': np.int64(441), '[ 7 22]': np.int64(442), '[ 7 23]': np.int64(443), '[ 7 24]': np.int64(444), '[ 7 25]': np.int64(445), '[ 7 26]': np.int64(446), '[ 7 27]': np.int64(447), '[ 7 28]': np.int64(448), '[ 7 29]': np.int64(449), '[ 7 30]': np.int64(450), '[ 7 31]': np.int64(451), '[ 7 32]': np.int64(452), '[ 7 33]': np.int64(453), '[ 7 34]': np.int64(454), '[ 7 35]': np.int64(455), '[ 7 36]': np.int64(456), '[ 7 37]': np.int64(457), '[ 7 38]': np.int64(458), '[ 7 39]': np.int64(459), '[ 7 40]': np.int64(460), '[ 7 41]': np.int64(461), '[ 7 42]': np.int64(462), '[ 7 43]': np.int64(463), '[ 7 44]': np.int64(464), '[ 7 45]': np.int64(465), '[ 7 46]': np.int64(466), '[ 7 47]': np.int64(467), '[ 7 48]': np.int64(468), '[ 7 49]': np.int64(469), '[ 7 50]': np.int64(470), '[ 7 51]': np.int64(471), '[ 7 52]': np.int64(472), '[ 7 53]': np.int64(473), '[ 7 54]': np.int64(474), '[ 7 55]': np.int64(475), '[ 7 56]': np.int64(476), '[ 7 57]': np.int64(477), '[ 7 58]': np.int64(478), '[ 7 59]': np.int64(479), '[8 0]': np.int64(480), '[8 1]': np.int64(481), '[8 2]': np.int64(482), '[8 3]': np.int64(483), '[8 4]': np.int64(484), '[8 5]': np.int64(485), '[8 6]': np.int64(486), '[8 7]': np.int64(487), '[8 8]': np.int64(488), '[8 9]': np.int64(489), '[ 8 10]': np.int64(490), '[ 8 11]': np.int64(491), '[ 8 12]': np.int64(492), '[ 8 13]': np.int64(493), '[ 8 14]': np.int64(494), '[ 8 15]': np.int64(495), '[ 8 16]': np.int64(496), '[ 8 17]': np.int64(497), '[ 8 18]': np.int64(498), '[ 8 19]': np.int64(499), '[ 8 20]': np.int64(500), '[ 8 21]': np.int64(501), '[ 8 22]': np.int64(502), '[ 8 23]': np.int64(503), '[ 8 24]': np.int64(504), '[ 8 25]': np.int64(505), '[ 8 26]': np.int64(506), '[ 8 27]': np.int64(507), '[ 8 28]': np.int64(508), '[ 8 29]': np.int64(509), '[ 8 30]': np.int64(510), '[ 8 31]': np.int64(511), '[ 8 32]': np.int64(512), '[ 8 33]': np.int64(513), '[ 8 34]': np.int64(514), '[ 8 35]': np.int64(515), '[ 8 36]': np.int64(516), '[ 8 37]': np.int64(517), '[ 8 38]': np.int64(518), '[ 8 39]': np.int64(519), '[ 8 40]': np.int64(520), '[ 8 41]': np.int64(521), '[ 8 42]': np.int64(522), '[ 8 43]': np.int64(523), '[ 8 44]': np.int64(524), '[ 8 45]': np.int64(525), '[ 8 46]': np.int64(526), '[ 8 47]': np.int64(527), '[ 8 48]': np.int64(528), '[ 8 49]': np.int64(529), '[ 8 50]': np.int64(530), '[ 8 51]': np.int64(531), '[ 8 52]': np.int64(532), '[ 8 53]': np.int64(533), '[ 8 54]': np.int64(534), '[ 8 55]': np.int64(535), '[ 8 56]': np.int64(536), '[ 8 57]': np.int64(537), '[ 8 58]': np.int64(538), '[ 8 59]': np.int64(539), '[9 0]': np.int64(540), '[9 1]': np.int64(541), '[9 2]': np.int64(542), '[9 3]': np.int64(543), '[9 4]': np.int64(544), '[9 5]': np.int64(545), '[9 6]': np.int64(546), '[9 7]': np.int64(547), '[9 8]': np.int64(548), '[9 9]': np.int64(549), '[ 9 10]': np.int64(550), '[ 9 11]': np.int64(551), '[ 9 12]': np.int64(552), '[ 9 13]': np.int64(553), '[ 9 14]': np.int64(554), '[ 9 15]': np.int64(555), '[ 9 16]': np.int64(556), '[ 9 17]': np.int64(557), '[ 9 18]': np.int64(558), '[ 9 19]': np.int64(559), '[ 9 20]': np.int64(560), '[ 9 21]': np.int64(561), '[ 9 22]': np.int64(562), '[ 9 23]': np.int64(563), '[ 9 24]': np.int64(564), '[ 9 25]': np.int64(565), '[ 9 26]': np.int64(566), '[ 9 27]': np.int64(567), '[ 9 28]': np.int64(568), '[ 9 29]': np.int64(569), '[ 9 30]': np.int64(570), '[ 9 31]': np.int64(571), '[ 9 32]': np.int64(572), '[ 9 33]': np.int64(573), '[ 9 34]': np.int64(574), '[ 9 35]': np.int64(575), '[ 9 36]': np.int64(576), '[ 9 37]': np.int64(577), '[ 9 38]': np.int64(578), '[ 9 39]': np.int64(579), '[ 9 40]': np.int64(580), '[ 9 41]': np.int64(581), '[ 9 42]': np.int64(582), '[ 9 43]': np.int64(583), '[ 9 44]': np.int64(584), '[ 9 45]': np.int64(585), '[ 9 46]': np.int64(586), '[ 9 47]': np.int64(587), '[ 9 48]': np.int64(588), '[ 9 49]': np.int64(589), '[ 9 50]': np.int64(590), '[ 9 51]': np.int64(591), '[ 9 52]': np.int64(592), '[ 9 53]': np.int64(593), '[ 9 54]': np.int64(594), '[ 9 55]': np.int64(595), '[ 9 56]': np.int64(596), '[ 9 57]': np.int64(597), '[ 9 58]': np.int64(598), '[ 9 59]': np.int64(599), '[10  0]': np.int64(600), '[10  1]': np.int64(601), '[10  2]': np.int64(602), '[10  3]': np.int64(603), '[10  4]': np.int64(604), '[10  5]': np.int64(605), '[10  6]': np.int64(606), '[10  7]': np.int64(607), '[10  8]': np.int64(608), '[10  9]': np.int64(609), '[10 10]': np.int64(610), '[10 11]': np.int64(611), '[10 12]': np.int64(612), '[10 13]': np.int64(613), '[10 14]': np.int64(614), '[10 15]': np.int64(615), '[10 16]': np.int64(616), '[10 17]': np.int64(617), '[10 18]': np.int64(618), '[10 19]': np.int64(619), '[10 20]': np.int64(620), '[10 21]': np.int64(621), '[10 22]': np.int64(622), '[10 23]': np.int64(623), '[10 24]': np.int64(624), '[10 25]': np.int64(625), '[10 26]': np.int64(626), '[10 27]': np.int64(627), '[10 28]': np.int64(628), '[10 29]': np.int64(629), '[10 30]': np.int64(630), '[10 31]': np.int64(631), '[10 32]': np.int64(632), '[10 33]': np.int64(633), '[10 34]': np.int64(634), '[10 35]': np.int64(635), '[10 36]': np.int64(636), '[10 37]': np.int64(637), '[10 38]': np.int64(638), '[10 39]': np.int64(639), '[10 40]': np.int64(640), '[10 41]': np.int64(641), '[10 42]': np.int64(642), '[10 43]': np.int64(643), '[10 44]': np.int64(644), '[10 45]': np.int64(645), '[10 46]': np.int64(646), '[10 47]': np.int64(647), '[10 48]': np.int64(648), '[10 49]': np.int64(649), '[10 50]': np.int64(650), '[10 51]': np.int64(651), '[10 52]': np.int64(652), '[10 53]': np.int64(653), '[10 54]': np.int64(654), '[10 55]': np.int64(655), '[10 56]': np.int64(656), '[10 57]': np.int64(657), '[10 58]': np.int64(658), '[10 59]': np.int64(659), '[11  0]': np.int64(660), '[11  1]': np.int64(661), '[11  2]': np.int64(662), '[11  3]': np.int64(663), '[11  4]': np.int64(664), '[11  5]': np.int64(665), '[11  6]': np.int64(666), '[11  7]': np.int64(667), '[11  8]': np.int64(668), '[11  9]': np.int64(669), '[11 10]': np.int64(670), '[11 11]': np.int64(671), '[11 12]': np.int64(672), '[11 13]': np.int64(673), '[11 14]': np.int64(674), '[11 15]': np.int64(675), '[11 16]': np.int64(676), '[11 17]': np.int64(677), '[11 18]': np.int64(678), '[11 19]': np.int64(679), '[11 20]': np.int64(680), '[11 21]': np.int64(681), '[11 22]': np.int64(682), '[11 23]': np.int64(683), '[11 24]': np.int64(684), '[11 25]': np.int64(685), '[11 26]': np.int64(686), '[11 27]': np.int64(687), '[11 28]': np.int64(688), '[11 29]': np.int64(689), '[11 30]': np.int64(690), '[11 31]': np.int64(691), '[11 32]': np.int64(692), '[11 33]': np.int64(693), '[11 34]': np.int64(694), '[11 35]': np.int64(695), '[11 36]': np.int64(696), '[11 37]': np.int64(697), '[11 38]': np.int64(698), '[11 39]': np.int64(699), '[11 40]': np.int64(700), '[11 41]': np.int64(701), '[11 42]': np.int64(702), '[11 43]': np.int64(703), '[11 44]': np.int64(704), '[11 45]': np.int64(705), '[11 46]': np.int64(706), '[11 47]': np.int64(707), '[11 48]': np.int64(708), '[11 49]': np.int64(709), '[11 50]': np.int64(710), '[11 51]': np.int64(711), '[11 52]': np.int64(712), '[11 53]': np.int64(713), '[11 54]': np.int64(714), '[11 55]': np.int64(715), '[11 56]': np.int64(716), '[11 57]': np.int64(717), '[11 58]': np.int64(718), '[11 59]': np.int64(719)}\n"
     ]
    }
   ],
   "source": [
    "labels = np.load(labels_path)\n",
    "def get_cat_labels_10(labels):\n",
    "    new_labels = []\n",
    "    dct = {}\n",
    "    for label in labels:\n",
    "        old = label\n",
    "        label = label[0]* 60 + int((label[1]))\n",
    "        new_labels.append(label)\n",
    "        dct[str(old)] = label\n",
    "    print(dct)\n",
    "    return np.array(new_labels)\n",
    "labels = get_cat_labels_10(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f0724e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 57 587 472 ... 223 268 344]\n"
     ]
    }
   ],
   "source": [
    "X_train_full, X_test,y_train_full, y_test = train_test_split(\n",
    "    images, labels, test_size=0.1, random_state=35\n",
    ")\n",
    "X_train, X_valid,y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=1/9, random_state=35\n",
    ") # 1/9 x 0.9 = 0.1. train test split shuffles by default\n",
    "print(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513c9086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_sense_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    y_pred_class = tf.argmax(y_pred, axis=1)\n",
    "    y_true_float = tf.cast(tf.squeeze(y_true), dtype=tf.float32)\n",
    "    y_pred_float = tf.cast(y_pred_class, dtype=tf.float32)\n",
    "    diff = tf.abs(y_true_float - y_pred_float)\n",
    "    cyclical_diff = tf.minimum(diff, 720.0 - diff)\n",
    "    print(cyclical_diff)\n",
    "    return tf.reduce_mean(cyclical_diff)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138eec7d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6306a9e",
   "metadata": {},
   "source": [
    "### (b) Regression\n",
    "\n",
    "try to build a network that predicts the time using a single output node in the\n",
    "following format: [”03 : 00” → y = 3.0]; [”05 : 30” → y = 5.5], where categorical labels of hours\n",
    "and minutes get transformed to a single continuous value. What kind of loss function would you\n",
    "need to use for such a task? What kind of problems does such a representation have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cc6f23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67102df4",
   "metadata": {},
   "source": [
    "### (c) Multi-head models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49100e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36461ab8",
   "metadata": {},
   "source": [
    "### (d) Label transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba594a92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7173647d",
   "metadata": {},
   "source": [
    "## 2\n",
    "Use the knowledge gained by working with other datasets in the previous parts of this assignment to\n",
    "optimize your final models and decrease the error of telling the time as much as possible (common\n",
    "sense error of below 10 minutes is achievable using relatively simple CNN architectures). You should\n",
    "also compare the different ways of representing your labels and different neural network output layer\n",
    "combinations. You should use an 80:20% ratio for the train/test sets respectively. Document your\n",
    "experiments and findings in the report."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cf0b427",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08c7a1f",
   "metadata": {},
   "source": [
    "Check out this official repository with many examples of Keras implementations of various sorts of\n",
    "deep neural networks here. We recommend cloning this repository and trying to get some of these\n",
    "examples running on your system (or Colab/DeepNote). In particular, experiment with mnist mlp.py\n",
    "and mnist cnn.py scripts which show you how to build simple neural networks for the MNIST dataset\n",
    "(useful for the next task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca5b5a0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Next, take the two well-known datasets: Fashion MNIST (introduced in Ch 10, p. 298) and CIFAR-10.\n",
    "The first dataset contains 2D (grayscale) images of size 28x28, split into 10 categories; 60,000 images\n",
    "for training and 10,000 for testing, while the latter contains 32x32x3 RGB images (50,000/10,000\n",
    "train/test). Apply two reference networks on the fashion MNIST datase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfa76a0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## (a) MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c553b63",
   "metadata": {},
   "source": [
    "initializations, activations, optimizers (and\n",
    "their hyperparameters), regularizations (L1, L2, Dropout, no Dropout). You may also experiment\n",
    "with changing the architecture of both networks: adding/removing layers, number of convolutional\n",
    "filters, their sizes, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fb077b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 13:50:14.388809: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-06 13:50:14.510098: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-06 13:50:20.316014: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96228793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "# Check number of available GPUs\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21235d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled memory growth for GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "(60000, 28, 28) (60000,)\n",
      "(55000, 28, 28) (55000,)\n",
      "(5000, 28, 28) (5000,)\n"
     ]
    }
   ],
   "source": [
    "# Use TensorFlow's bundled Keras to ensure compatibility with GPUs\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "random_state = 900\n",
    "keras.utils.set_random_seed(random_state)\n",
    "\n",
    "# Try to enable memory growth for all GPUs so TF doesn't reserve all GPU memory upfront\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print('Enabled memory growth for GPUs:', gpus)\n",
    "    except Exception as e:\n",
    "        print('Could not set memory growth:', e)\n",
    "else:\n",
    "    print('No GPU devices found by TensorFlow')\n",
    "\n",
    "\n",
    "\n",
    "fashion_mnist= keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
    "print(X_train_full.shape, y_train_full.shape)\n",
    "\n",
    "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "\n",
    "X_test = X_test / 255.0\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_valid.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176522c5",
   "metadata": {},
   "source": [
    "### Model 1\n",
    "\n",
    "Below is our first attempt at building a neural network. We use the SGD optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6a17ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_13\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_13\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_58 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">314,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_59 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">80,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_60 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_61 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,040</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_62 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">410</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_13 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_58 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m)            │       \u001b[38;5;34m314,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_34 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_59 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │        \u001b[38;5;34m80,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_35 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_60 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m20,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_36 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_61 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)             │         \u001b[38;5;34m4,040\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_62 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m410\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">418,750</span> (1.60 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m418,750\u001b[0m (1.60 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">418,750</span> (1.60 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m418,750\u001b[0m (1.60 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 12:54:24.110812: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2025-11-06 12:54:24.321389: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1474', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2025-11-06 12:54:24.344781: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1474', 44 bytes spill stores, 44 bytes spill loads\n",
      "\n",
      "2025-11-06 12:54:24.485684: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1474', 368 bytes spill stores, 368 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.6762 - loss: 1.0317 - val_accuracy: 0.7982 - val_loss: 0.6764\n",
      "Epoch 2/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 790us/step - accuracy: 0.7947 - loss: 0.6742 - val_accuracy: 0.8346 - val_loss: 0.5760\n",
      "Epoch 3/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 661us/step - accuracy: 0.8200 - loss: 0.6048 - val_accuracy: 0.8478 - val_loss: 0.5369\n",
      "Epoch 4/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 808us/step - accuracy: 0.8331 - loss: 0.5642 - val_accuracy: 0.8542 - val_loss: 0.5124\n",
      "Epoch 5/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 737us/step - accuracy: 0.8410 - loss: 0.5390 - val_accuracy: 0.8596 - val_loss: 0.4961\n",
      "Epoch 6/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 748us/step - accuracy: 0.8497 - loss: 0.5175 - val_accuracy: 0.8644 - val_loss: 0.4813\n",
      "Epoch 7/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 772us/step - accuracy: 0.8528 - loss: 0.5027 - val_accuracy: 0.8692 - val_loss: 0.4692\n",
      "Epoch 8/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 728us/step - accuracy: 0.8591 - loss: 0.4884 - val_accuracy: 0.8710 - val_loss: 0.4585\n",
      "Epoch 9/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 732us/step - accuracy: 0.8619 - loss: 0.4758 - val_accuracy: 0.8738 - val_loss: 0.4507\n",
      "Epoch 10/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 679us/step - accuracy: 0.8666 - loss: 0.4637 - val_accuracy: 0.8752 - val_loss: 0.4447\n",
      "Epoch 11/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 674us/step - accuracy: 0.8691 - loss: 0.4555 - val_accuracy: 0.8754 - val_loss: 0.4380\n",
      "Epoch 12/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 744us/step - accuracy: 0.8715 - loss: 0.4478 - val_accuracy: 0.8774 - val_loss: 0.4342\n",
      "Epoch 13/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 710us/step - accuracy: 0.8734 - loss: 0.4399 - val_accuracy: 0.8794 - val_loss: 0.4305\n",
      "Epoch 14/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 683us/step - accuracy: 0.8754 - loss: 0.4324 - val_accuracy: 0.8802 - val_loss: 0.4263\n",
      "Epoch 15/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 679us/step - accuracy: 0.8800 - loss: 0.4264 - val_accuracy: 0.8828 - val_loss: 0.4250\n",
      "Epoch 16/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 768us/step - accuracy: 0.8807 - loss: 0.4193 - val_accuracy: 0.8846 - val_loss: 0.4175\n",
      "Epoch 17/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 670us/step - accuracy: 0.8828 - loss: 0.4150 - val_accuracy: 0.8836 - val_loss: 0.4140\n",
      "Epoch 18/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 702us/step - accuracy: 0.8853 - loss: 0.4097 - val_accuracy: 0.8854 - val_loss: 0.4112\n",
      "Epoch 19/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 699us/step - accuracy: 0.8855 - loss: 0.4049 - val_accuracy: 0.8874 - val_loss: 0.4094\n",
      "Epoch 20/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 684us/step - accuracy: 0.8877 - loss: 0.3984 - val_accuracy: 0.8894 - val_loss: 0.4077\n",
      "Epoch 21/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 701us/step - accuracy: 0.8881 - loss: 0.3951 - val_accuracy: 0.8854 - val_loss: 0.4065\n",
      "Epoch 22/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 671us/step - accuracy: 0.8907 - loss: 0.3912 - val_accuracy: 0.8874 - val_loss: 0.4036\n",
      "Epoch 23/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 684us/step - accuracy: 0.8913 - loss: 0.3876 - val_accuracy: 0.8894 - val_loss: 0.4019\n",
      "Epoch 24/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 727us/step - accuracy: 0.8933 - loss: 0.3834 - val_accuracy: 0.8904 - val_loss: 0.3992\n",
      "Epoch 25/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 699us/step - accuracy: 0.8947 - loss: 0.3793 - val_accuracy: 0.8900 - val_loss: 0.3983\n",
      "Epoch 26/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 679us/step - accuracy: 0.8961 - loss: 0.3737 - val_accuracy: 0.8890 - val_loss: 0.3948\n",
      "Epoch 27/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 714us/step - accuracy: 0.8970 - loss: 0.3715 - val_accuracy: 0.8884 - val_loss: 0.3931\n",
      "Epoch 28/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 684us/step - accuracy: 0.8989 - loss: 0.3658 - val_accuracy: 0.8918 - val_loss: 0.3930\n",
      "Epoch 29/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 720us/step - accuracy: 0.8994 - loss: 0.3633 - val_accuracy: 0.8868 - val_loss: 0.3980\n",
      "Epoch 30/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 687us/step - accuracy: 0.9002 - loss: 0.3596 - val_accuracy: 0.8938 - val_loss: 0.3911\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x70fca8773a40>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## First attempt\n",
    "\n",
    "# Build model\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(400, activation='leaky_relu', kernel_regularizer=keras.regularizers.l2(0.0001)),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(200, activation=\"leaky_relu\", kernel_regularizer=keras.regularizers.l2(0.0001)),\n",
    "    keras.layers.Dropout(0.05),\n",
    "    keras.layers.Dense(100, activation=\"leaky_relu\"),\n",
    "    keras.layers.Dropout(0.05),\n",
    "    keras.layers.Dense(40, activation=\"leaky_relu\"),    \n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    patience=6,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "optimizer=keras.optimizers.SGD(learning_rate=5e-3),\n",
    "metrics=[\"accuracy\",\n",
    "        #   tf.keras.metrics.Precision(), tf.keras.metrics.Recall()\n",
    "          ])\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=60,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=[early_stopping]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d25b01ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8812 - loss: 0.4220\n",
      "Test accuracy: 0.8812000155448914\n",
      "Test loss: 0.42198416590690613\n"
     ]
    }
   ],
   "source": [
    "#evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', test_acc)\n",
    "print('Test loss:', test_loss)\n",
    "#0.8834999799728394"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee21434",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78b8ded8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m## second attempt\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Build model\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m model = \u001b[43mkeras\u001b[49m.models.Sequential([\n\u001b[32m      5\u001b[39m     keras.layers.Flatten(input_shape=[\u001b[32m28\u001b[39m, \u001b[32m28\u001b[39m]),\n\u001b[32m      6\u001b[39m     keras.layers.Dense(\u001b[32m300\u001b[39m, activation=\u001b[33m'\u001b[39m\u001b[33mleaky_relu\u001b[39m\u001b[33m'\u001b[39m, kernel_regularizer=keras.regularizers.l2(\u001b[32m0.0001\u001b[39m)),\n\u001b[32m      7\u001b[39m     keras.layers.Dropout(\u001b[32m0.1\u001b[39m),\n\u001b[32m      8\u001b[39m     keras.layers.Dense(\u001b[32m100\u001b[39m, activation=\u001b[33m\"\u001b[39m\u001b[33mleaky_relu\u001b[39m\u001b[33m\"\u001b[39m, kernel_regularizer=keras.regularizers.l2(\u001b[32m0.0001\u001b[39m)),\n\u001b[32m      9\u001b[39m     keras.layers.Dropout(\u001b[32m0.05\u001b[39m),\n\u001b[32m     10\u001b[39m     keras.layers.Dense(\u001b[32m100\u001b[39m, activation=\u001b[33m\"\u001b[39m\u001b[33mleaky_relu\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     11\u001b[39m     keras.layers.Dropout(\u001b[32m0.05\u001b[39m),\n\u001b[32m     12\u001b[39m     keras.layers.Dense(\u001b[32m30\u001b[39m, activation=\u001b[33m\"\u001b[39m\u001b[33mleaky_relu\u001b[39m\u001b[33m\"\u001b[39m),    \n\u001b[32m     13\u001b[39m     keras.layers.Dense(\u001b[32m10\u001b[39m, activation=\u001b[33m\"\u001b[39m\u001b[33msoftmax\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     14\u001b[39m ])\n\u001b[32m     15\u001b[39m early_stopping = keras.callbacks.EarlyStopping(\n\u001b[32m     16\u001b[39m     patience=\u001b[32m6\u001b[39m,\n\u001b[32m     17\u001b[39m     restore_best_weights=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     18\u001b[39m )\n\u001b[32m     20\u001b[39m model.summary()\n",
      "\u001b[31mNameError\u001b[39m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "## second attempt\n",
    "\n",
    "# Build model\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation='leaky_relu', kernel_regularizer=keras.regularizers.l2(0.0001)),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(100, activation=\"leaky_relu\", kernel_regularizer=keras.regularizers.l2(0.0001)),\n",
    "    keras.layers.Dropout(0.05),\n",
    "    keras.layers.Dense(100, activation=\"leaky_relu\"),\n",
    "    keras.layers.Dropout(0.05),\n",
    "    keras.layers.Dense(30, activation=\"leaky_relu\"),    \n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    patience=6,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "metrics=[\"accuracy\",\n",
    "        #   tf.keras.metrics.Precision(), tf.keras.metrics.Recall()\n",
    "          ])\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=60,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=[early_stopping]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8a1149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.8750 - loss: 0.5421"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8867 - loss: 0.3845\n",
      "Test accuracy: 0.8866999745368958\n",
      "Test loss: 0.38445159792900085\n"
     ]
    }
   ],
   "source": [
    "#evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', test_acc)\n",
    "print('Test loss:', test_loss)\n",
    "#0.8866999745368958"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79aa9e8",
   "metadata": {},
   "source": [
    "## (b) CNN\n",
    "\n",
    "Here we make a model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e977bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pool = keras.layers.MaxPool2D(pool_size=2)\n",
    "# avg_pool = keras.layers.AveragePooling2D(pool_size=2)\n",
    "model = keras.models.Sequential([\n",
    "keras.layers.Conv2D(64, 7, activation=\"leaky_relu\", padding=\"same\",\n",
    "input_shape=[28, 28, 1]),\n",
    "keras.layers.BatchNormalization(),\n",
    "keras.layers.MaxPooling2D(2),\n",
    "keras.layers.Conv2D(128, 3, activation=\"leaky_relu\", padding=\"same\"),\n",
    "keras.layers.BatchNormalization(),\n",
    "keras.layers.Conv2D(128, 3, activation=\"leaky_relu\", padding=\"same\"),\n",
    "keras.layers.BatchNormalization(),\n",
    "keras.layers.MaxPooling2D(2),\n",
    "# keras.layers.Dropout(0.12,\n",
    "keras.layers.Conv2D(256, 3, activation=\"leaky_relu\", padding=\"same\"),\n",
    "keras.layers.BatchNormalization(),\n",
    "keras.layers.Conv2D(256, 3, activation=\"leaky_relu\", padding=\"same\"),\n",
    "keras.layers.BatchNormalization(),\n",
    "keras.layers.MaxPooling2D(2),\n",
    "keras.layers.Flatten(),\n",
    "keras.layers.Dense(128, activation=\"leaky_relu\"),\n",
    "keras.layers.Dropout(0.5),\n",
    "keras.layers.Dense(64, activation=\"leaky_relu\"),\n",
    "keras.layers.Dropout(0.5),\n",
    "keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "optimizer=keras.optimizers.SGD(learning_rate=2e-3),\n",
    "metrics=[\"accuracy\",\n",
    "        #   tf.keras.metrics.Precision(), tf.keras.metrics.Recall()\n",
    "          ])\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=30,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    # callbacks=[early_stopping]\n",
    ")\n",
    "#evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', test_acc)\n",
    "#base:0.8420000076293945\n",
    "#leaky: 0.8525000214576721\n",
    "#leaky + L2regularization: 0.8472999930381775\n",
    "#leaky + batch normalization: 0.8978000283241272\n",
    "\n",
    "(print(tf.__version__))\n",
    "# metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040bbd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a619f6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IDL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "192faa0b",
   "metadata": {},
   "source": [
    "The dataset can be downloaded from here and it consists of 18000 grayscale images (18000x150x150\n",
    "or 18000x75x75) contained in ‘images.npy’. The labels for each sample are represented by two integers\n",
    "(18000x2, ‘labels.npy’ file), that correspond to the hour and minute displayed by the clock. You can see\n",
    "that each image is rendered from a different angle and rotation and they might contain light reflections from\n",
    "within the scene making this a non-trivial problem. For your experiments, we suggest splitting your data\n",
    "into 80/10/10% splits for training/validation and test sets respectively. Remember to shuffle your dataset\n",
    "as the sample files are ordered. We suggest using the smaller dataset for your initial tests and runs (75x75\n",
    "images) and then reporting your results on the larger (150x150) datase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6683c775",
   "metadata": {},
   "source": [
    "## GPU CHECK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "70ab1639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.20.0\n",
      "TensorFlow detected 1 GPU(s):\n",
      "  - /physical_device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow  as tf\n",
    "print(tf.__version__)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"TensorFlow detected {len(gpus)} GPU(s):\")\n",
    "    for gpu in gpus:\n",
    "        print(f\"  - {gpu.name}\")\n",
    "else:\n",
    "    print(\"TensorFlow did NOT detect any GPUs. It will use the CPU.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907b0a97",
   "metadata": {},
   "source": [
    "#### import needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "421d4afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from tensorflow import keras\n",
    "import os\n",
    "# import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "import keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49a8dc3",
   "metadata": {},
   "source": [
    "#### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f46e7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"A1_data_75\"\n",
    "images_path = os.path.join(data_folder, \"images.npy\")\n",
    "images = np.load(images_path)\n",
    "labels_path = os.path.join(data_folder, \"labels.npy\")\n",
    "labels = np.load(labels_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c526553d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "599be172",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0df874d1",
   "metadata": {},
   "source": [
    "(a) Classification - treat this as a n-class classification problem. We suggest starting out with a\n",
    "smaller number of categories e.g. grouping all the samples that are between [3 : 00 −3 : 30] into\n",
    "a single category (results in 24 categories in total), and trying to train a CNN model. Once you\n",
    "have found a working architecture, increase the number of categories by using smaller intervals\n",
    "for grouping samples to increase the ’common sense accuracy’. Can you train a network using\n",
    "all 720 different labels? What problems does such a label representation have?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d05f0fd",
   "metadata": {},
   "source": [
    "## Task a: classification\n",
    "We will start with deviding labels into 24 categories, one for each 30 minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b7cc7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0]\n",
      " [ 0  0]\n",
      " [ 0  0]\n",
      " ...\n",
      " [11 59]\n",
      " [11 59]\n",
      " [11 59]]\n",
      "[ 0  0  0 ... 23 23 23]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(labels)\n",
    "def get_cat_labels(labels):\n",
    "    new_labels = []\n",
    "    for label in labels:\n",
    "        label = label[0]* 2 + int(label[1] >= 30)\n",
    "        new_labels.append(label)\n",
    "    return np.array(new_labels)\n",
    "labels = get_cat_labels(labels)\n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a59933",
   "metadata": {},
   "source": [
    "We then split the data into training, validation, and test sets. The sklearn train_test_split method shuffles the data by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0460928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (14400, 75, 75)\n",
      "y_train shape: (14400,)\n",
      "X_valid shape: (1800, 75, 75)\n",
      "y_valid shape: (1800,)\n",
      "X_test shape: (1800, 75, 75)\n",
      "y_test shape: (1800,)\n"
     ]
    }
   ],
   "source": [
    "X_train_full, X_test,y_train_full, y_test = train_test_split(\n",
    "    images, labels, test_size=0.1, random_state=35\n",
    ")\n",
    "X_train, X_valid,y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=1/9, random_state=35\n",
    ") # 1/9 x 0.9 = 0.1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0363c8",
   "metadata": {},
   "source": [
    "we define a common sense loss. This will calculate how far of the prediction was"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2865ea1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_sense_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    y_pred_class = tf.argmax(y_pred, axis=1)\n",
    "    y_true_float = tf.cast(tf.squeeze(y_true), dtype=tf.float32)\n",
    "    y_pred_float = tf.cast(y_pred_class, dtype=tf.float32)\n",
    "    diff = tf.abs(y_true_float - y_pred_float)\n",
    "    cyclical_diff = tf.minimum(diff, 12.0 - diff)\n",
    "    print(cyclical_diff)\n",
    "    return tf.reduce_mean(cyclical_diff)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2e45f7",
   "metadata": {},
   "source": [
    "Our model for 24 class classification. We use a scheduler to lower the learning rate when we plateau\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fb4aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lr_scheduler = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,          # halve the learning rate if there is no improvement\n",
    "    patience=3,          # Wait 2 epochs with no improvement before reducing\n",
    "    min_lr=1e-6          # Set a minimum learning rate at 1e-6\n",
    ")\n",
    "early_stopper = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=6,          # Wait 6 epochs for improvement before stopping\n",
    "    restore_best_weights=True  # Automatically restore the weights from the best epoch\n",
    ")\n",
    "model = keras.models.Sequential([\n",
    "    keras.Input(shape=(75, 75, 1)),\n",
    "    # Block 1\n",
    "    keras.layers.Conv2D(32, (3,3), activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    # Block 2\n",
    "    keras.layers.Conv2D(64, (3,3), activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(64, (3,3), activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPooling2D(2),\n",
    "\n",
    "    # Block 3\n",
    "    keras.layers.Conv2D(128, (3,3), activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(128, (3,3), activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPooling2D(2), # Output shape: (9, 9, 128)\n",
    "\n",
    "    # Block 4\n",
    "    keras.layers.Conv2D(256, (3,3), activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPooling2D(2), # Output shape: (4, 4, 256)\n",
    "\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128, activation=\"leaky_relu\"),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(64, activation=\"leaky_relu\"),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(24, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "metrics=[common_sense_loss,\"Accuracy\"\n",
    "        #   tf.keras.metrics.Precision(), tf.keras.metrics.Recall()\n",
    "          ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d76ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - Accuracy: 0.9581 - common_sense_loss: 0.0559 - loss: 0.1244 - val_Accuracy: 0.9578 - val_common_sense_loss: 0.0351 - val_loss: 0.1369 - learning_rate: 3.1250e-05\n",
      "Epoch 2/10\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - Accuracy: 0.9596 - common_sense_loss: 0.0474 - loss: 0.1199 - val_Accuracy: 0.9594 - val_common_sense_loss: 0.0389 - val_loss: 0.1259 - learning_rate: 3.1250e-05\n",
      "Epoch 3/10\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - Accuracy: 0.9624 - common_sense_loss: 0.0453 - loss: 0.1182 - val_Accuracy: 0.9517 - val_common_sense_loss: 0.0515 - val_loss: 0.1607 - learning_rate: 3.1250e-05\n",
      "Epoch 4/10\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - Accuracy: 0.9633 - common_sense_loss: 0.0463 - loss: 0.1117 - val_Accuracy: 0.9589 - val_common_sense_loss: 0.0417 - val_loss: 0.1299 - learning_rate: 3.1250e-05\n",
      "Epoch 5/10\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - Accuracy: 0.9642 - common_sense_loss: 0.0422 - loss: 0.1092 - val_Accuracy: 0.9594 - val_common_sense_loss: 0.0482 - val_loss: 0.1330 - learning_rate: 1.5625e-05\n",
      "Epoch 6/10\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - Accuracy: 0.9665 - common_sense_loss: 0.0440 - loss: 0.0996 - val_Accuracy: 0.9628 - val_common_sense_loss: 0.0378 - val_loss: 0.1279 - learning_rate: 1.5625e-05\n",
      "Epoch 7/10\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - Accuracy: 0.9651 - common_sense_loss: 0.0481 - loss: 0.1046 - val_Accuracy: 0.9667 - val_common_sense_loss: 0.0351 - val_loss: 0.1242 - learning_rate: 7.8125e-06\n",
      "Epoch 8/10\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - Accuracy: 0.9706 - common_sense_loss: 0.0360 - loss: 0.0927 - val_Accuracy: 0.9644 - val_common_sense_loss: 0.0384 - val_loss: 0.1248 - learning_rate: 7.8125e-06\n",
      "Epoch 9/10\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - Accuracy: 0.9678 - common_sense_loss: 0.0418 - loss: 0.0954 - val_Accuracy: 0.9650 - val_common_sense_loss: 0.0444 - val_loss: 0.1275 - learning_rate: 7.8125e-06\n",
      "Epoch 10/10\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - Accuracy: 0.9688 - common_sense_loss: 0.0388 - loss: 0.0968 - val_Accuracy: 0.9633 - val_common_sense_loss: 0.0400 - val_loss: 0.1261 - learning_rate: 3.9063e-06\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - Accuracy: 0.9711 - common_sense_loss: 0.0252 - loss: 0.1144\n",
      "Test accuracy: 0.9711111187934875\n",
      "2.20.0\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=10,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=[lr_scheduler, early_stopper]\n",
    "    )\n",
    "#evaluate the model on the test set\n",
    "test_loss,test_csl, test_acc = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', test_acc)\n",
    "#base:0.8420000076293945\n",
    "#leaky: 0.8525000214576721\n",
    "#leaky + L2regularization: 0.8472999930381775\n",
    "#leaky + batch normalization: 0.8978000283241272\n",
    "\n",
    "(print(tf.__version__))\n",
    "#0.9711111187934875\n",
    "# metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde39a1f",
   "metadata": {},
   "source": [
    "We now make a class for every 10 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543285f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'[0 0]': np.int64(0), '[0 1]': np.int64(0), '[0 2]': np.int64(0), '[0 3]': np.int64(0), '[0 4]': np.int64(0), '[0 5]': np.int64(0), '[0 6]': np.int64(0), '[0 7]': np.int64(0), '[0 8]': np.int64(0), '[0 9]': np.int64(0), '[ 0 10]': np.int64(1), '[ 0 11]': np.int64(1), '[ 0 12]': np.int64(1), '[ 0 13]': np.int64(1), '[ 0 14]': np.int64(1), '[ 0 15]': np.int64(1), '[ 0 16]': np.int64(1), '[ 0 17]': np.int64(1), '[ 0 18]': np.int64(1), '[ 0 19]': np.int64(1), '[ 0 20]': np.int64(2), '[ 0 21]': np.int64(2), '[ 0 22]': np.int64(2), '[ 0 23]': np.int64(2), '[ 0 24]': np.int64(2), '[ 0 25]': np.int64(2), '[ 0 26]': np.int64(2), '[ 0 27]': np.int64(2), '[ 0 28]': np.int64(2), '[ 0 29]': np.int64(2), '[ 0 30]': np.int64(3), '[ 0 31]': np.int64(3), '[ 0 32]': np.int64(3), '[ 0 33]': np.int64(3), '[ 0 34]': np.int64(3), '[ 0 35]': np.int64(3), '[ 0 36]': np.int64(3), '[ 0 37]': np.int64(3), '[ 0 38]': np.int64(3), '[ 0 39]': np.int64(3), '[ 0 40]': np.int64(4), '[ 0 41]': np.int64(4), '[ 0 42]': np.int64(4), '[ 0 43]': np.int64(4), '[ 0 44]': np.int64(4), '[ 0 45]': np.int64(4), '[ 0 46]': np.int64(4), '[ 0 47]': np.int64(4), '[ 0 48]': np.int64(4), '[ 0 49]': np.int64(4), '[ 0 50]': np.int64(5), '[ 0 51]': np.int64(5), '[ 0 52]': np.int64(5), '[ 0 53]': np.int64(5), '[ 0 54]': np.int64(5), '[ 0 55]': np.int64(5), '[ 0 56]': np.int64(5), '[ 0 57]': np.int64(5), '[ 0 58]': np.int64(5), '[ 0 59]': np.int64(5), '[1 0]': np.int64(6), '[1 1]': np.int64(6), '[1 2]': np.int64(6), '[1 3]': np.int64(6), '[1 4]': np.int64(6), '[1 5]': np.int64(6), '[1 6]': np.int64(6), '[1 7]': np.int64(6), '[1 8]': np.int64(6), '[1 9]': np.int64(6), '[ 1 10]': np.int64(7), '[ 1 11]': np.int64(7), '[ 1 12]': np.int64(7), '[ 1 13]': np.int64(7), '[ 1 14]': np.int64(7), '[ 1 15]': np.int64(7), '[ 1 16]': np.int64(7), '[ 1 17]': np.int64(7), '[ 1 18]': np.int64(7), '[ 1 19]': np.int64(7), '[ 1 20]': np.int64(8), '[ 1 21]': np.int64(8), '[ 1 22]': np.int64(8), '[ 1 23]': np.int64(8), '[ 1 24]': np.int64(8), '[ 1 25]': np.int64(8), '[ 1 26]': np.int64(8), '[ 1 27]': np.int64(8), '[ 1 28]': np.int64(8), '[ 1 29]': np.int64(8), '[ 1 30]': np.int64(9), '[ 1 31]': np.int64(9), '[ 1 32]': np.int64(9), '[ 1 33]': np.int64(9), '[ 1 34]': np.int64(9), '[ 1 35]': np.int64(9), '[ 1 36]': np.int64(9), '[ 1 37]': np.int64(9), '[ 1 38]': np.int64(9), '[ 1 39]': np.int64(9), '[ 1 40]': np.int64(10), '[ 1 41]': np.int64(10), '[ 1 42]': np.int64(10), '[ 1 43]': np.int64(10), '[ 1 44]': np.int64(10), '[ 1 45]': np.int64(10), '[ 1 46]': np.int64(10), '[ 1 47]': np.int64(10), '[ 1 48]': np.int64(10), '[ 1 49]': np.int64(10), '[ 1 50]': np.int64(11), '[ 1 51]': np.int64(11), '[ 1 52]': np.int64(11), '[ 1 53]': np.int64(11), '[ 1 54]': np.int64(11), '[ 1 55]': np.int64(11), '[ 1 56]': np.int64(11), '[ 1 57]': np.int64(11), '[ 1 58]': np.int64(11), '[ 1 59]': np.int64(11), '[2 0]': np.int64(12), '[2 1]': np.int64(12), '[2 2]': np.int64(12), '[2 3]': np.int64(12), '[2 4]': np.int64(12), '[2 5]': np.int64(12), '[2 6]': np.int64(12), '[2 7]': np.int64(12), '[2 8]': np.int64(12), '[2 9]': np.int64(12), '[ 2 10]': np.int64(13), '[ 2 11]': np.int64(13), '[ 2 12]': np.int64(13), '[ 2 13]': np.int64(13), '[ 2 14]': np.int64(13), '[ 2 15]': np.int64(13), '[ 2 16]': np.int64(13), '[ 2 17]': np.int64(13), '[ 2 18]': np.int64(13), '[ 2 19]': np.int64(13), '[ 2 20]': np.int64(14), '[ 2 21]': np.int64(14), '[ 2 22]': np.int64(14), '[ 2 23]': np.int64(14), '[ 2 24]': np.int64(14), '[ 2 25]': np.int64(14), '[ 2 26]': np.int64(14), '[ 2 27]': np.int64(14), '[ 2 28]': np.int64(14), '[ 2 29]': np.int64(14), '[ 2 30]': np.int64(15), '[ 2 31]': np.int64(15), '[ 2 32]': np.int64(15), '[ 2 33]': np.int64(15), '[ 2 34]': np.int64(15), '[ 2 35]': np.int64(15), '[ 2 36]': np.int64(15), '[ 2 37]': np.int64(15), '[ 2 38]': np.int64(15), '[ 2 39]': np.int64(15), '[ 2 40]': np.int64(16), '[ 2 41]': np.int64(16), '[ 2 42]': np.int64(16), '[ 2 43]': np.int64(16), '[ 2 44]': np.int64(16), '[ 2 45]': np.int64(16), '[ 2 46]': np.int64(16), '[ 2 47]': np.int64(16), '[ 2 48]': np.int64(16), '[ 2 49]': np.int64(16), '[ 2 50]': np.int64(17), '[ 2 51]': np.int64(17), '[ 2 52]': np.int64(17), '[ 2 53]': np.int64(17), '[ 2 54]': np.int64(17), '[ 2 55]': np.int64(17), '[ 2 56]': np.int64(17), '[ 2 57]': np.int64(17), '[ 2 58]': np.int64(17), '[ 2 59]': np.int64(17), '[3 0]': np.int64(18), '[3 1]': np.int64(18), '[3 2]': np.int64(18), '[3 3]': np.int64(18), '[3 4]': np.int64(18), '[3 5]': np.int64(18), '[3 6]': np.int64(18), '[3 7]': np.int64(18), '[3 8]': np.int64(18), '[3 9]': np.int64(18), '[ 3 10]': np.int64(19), '[ 3 11]': np.int64(19), '[ 3 12]': np.int64(19), '[ 3 13]': np.int64(19), '[ 3 14]': np.int64(19), '[ 3 15]': np.int64(19), '[ 3 16]': np.int64(19), '[ 3 17]': np.int64(19), '[ 3 18]': np.int64(19), '[ 3 19]': np.int64(19), '[ 3 20]': np.int64(20), '[ 3 21]': np.int64(20), '[ 3 22]': np.int64(20), '[ 3 23]': np.int64(20), '[ 3 24]': np.int64(20), '[ 3 25]': np.int64(20), '[ 3 26]': np.int64(20), '[ 3 27]': np.int64(20), '[ 3 28]': np.int64(20), '[ 3 29]': np.int64(20), '[ 3 30]': np.int64(21), '[ 3 31]': np.int64(21), '[ 3 32]': np.int64(21), '[ 3 33]': np.int64(21), '[ 3 34]': np.int64(21), '[ 3 35]': np.int64(21), '[ 3 36]': np.int64(21), '[ 3 37]': np.int64(21), '[ 3 38]': np.int64(21), '[ 3 39]': np.int64(21), '[ 3 40]': np.int64(22), '[ 3 41]': np.int64(22), '[ 3 42]': np.int64(22), '[ 3 43]': np.int64(22), '[ 3 44]': np.int64(22), '[ 3 45]': np.int64(22), '[ 3 46]': np.int64(22), '[ 3 47]': np.int64(22), '[ 3 48]': np.int64(22), '[ 3 49]': np.int64(22), '[ 3 50]': np.int64(23), '[ 3 51]': np.int64(23), '[ 3 52]': np.int64(23), '[ 3 53]': np.int64(23), '[ 3 54]': np.int64(23), '[ 3 55]': np.int64(23), '[ 3 56]': np.int64(23), '[ 3 57]': np.int64(23), '[ 3 58]': np.int64(23), '[ 3 59]': np.int64(23), '[4 0]': np.int64(24), '[4 1]': np.int64(24), '[4 2]': np.int64(24), '[4 3]': np.int64(24), '[4 4]': np.int64(24), '[4 5]': np.int64(24), '[4 6]': np.int64(24), '[4 7]': np.int64(24), '[4 8]': np.int64(24), '[4 9]': np.int64(24), '[ 4 10]': np.int64(25), '[ 4 11]': np.int64(25), '[ 4 12]': np.int64(25), '[ 4 13]': np.int64(25), '[ 4 14]': np.int64(25), '[ 4 15]': np.int64(25), '[ 4 16]': np.int64(25), '[ 4 17]': np.int64(25), '[ 4 18]': np.int64(25), '[ 4 19]': np.int64(25), '[ 4 20]': np.int64(26), '[ 4 21]': np.int64(26), '[ 4 22]': np.int64(26), '[ 4 23]': np.int64(26), '[ 4 24]': np.int64(26), '[ 4 25]': np.int64(26), '[ 4 26]': np.int64(26), '[ 4 27]': np.int64(26), '[ 4 28]': np.int64(26), '[ 4 29]': np.int64(26), '[ 4 30]': np.int64(27), '[ 4 31]': np.int64(27), '[ 4 32]': np.int64(27), '[ 4 33]': np.int64(27), '[ 4 34]': np.int64(27), '[ 4 35]': np.int64(27), '[ 4 36]': np.int64(27), '[ 4 37]': np.int64(27), '[ 4 38]': np.int64(27), '[ 4 39]': np.int64(27), '[ 4 40]': np.int64(28), '[ 4 41]': np.int64(28), '[ 4 42]': np.int64(28), '[ 4 43]': np.int64(28), '[ 4 44]': np.int64(28), '[ 4 45]': np.int64(28), '[ 4 46]': np.int64(28), '[ 4 47]': np.int64(28), '[ 4 48]': np.int64(28), '[ 4 49]': np.int64(28), '[ 4 50]': np.int64(29), '[ 4 51]': np.int64(29), '[ 4 52]': np.int64(29), '[ 4 53]': np.int64(29), '[ 4 54]': np.int64(29), '[ 4 55]': np.int64(29), '[ 4 56]': np.int64(29), '[ 4 57]': np.int64(29), '[ 4 58]': np.int64(29), '[ 4 59]': np.int64(29), '[5 0]': np.int64(30), '[5 1]': np.int64(30), '[5 2]': np.int64(30), '[5 3]': np.int64(30), '[5 4]': np.int64(30), '[5 5]': np.int64(30), '[5 6]': np.int64(30), '[5 7]': np.int64(30), '[5 8]': np.int64(30), '[5 9]': np.int64(30), '[ 5 10]': np.int64(31), '[ 5 11]': np.int64(31), '[ 5 12]': np.int64(31), '[ 5 13]': np.int64(31), '[ 5 14]': np.int64(31), '[ 5 15]': np.int64(31), '[ 5 16]': np.int64(31), '[ 5 17]': np.int64(31), '[ 5 18]': np.int64(31), '[ 5 19]': np.int64(31), '[ 5 20]': np.int64(32), '[ 5 21]': np.int64(32), '[ 5 22]': np.int64(32), '[ 5 23]': np.int64(32), '[ 5 24]': np.int64(32), '[ 5 25]': np.int64(32), '[ 5 26]': np.int64(32), '[ 5 27]': np.int64(32), '[ 5 28]': np.int64(32), '[ 5 29]': np.int64(32), '[ 5 30]': np.int64(33), '[ 5 31]': np.int64(33), '[ 5 32]': np.int64(33), '[ 5 33]': np.int64(33), '[ 5 34]': np.int64(33), '[ 5 35]': np.int64(33), '[ 5 36]': np.int64(33), '[ 5 37]': np.int64(33), '[ 5 38]': np.int64(33), '[ 5 39]': np.int64(33), '[ 5 40]': np.int64(34), '[ 5 41]': np.int64(34), '[ 5 42]': np.int64(34), '[ 5 43]': np.int64(34), '[ 5 44]': np.int64(34), '[ 5 45]': np.int64(34), '[ 5 46]': np.int64(34), '[ 5 47]': np.int64(34), '[ 5 48]': np.int64(34), '[ 5 49]': np.int64(34), '[ 5 50]': np.int64(35), '[ 5 51]': np.int64(35), '[ 5 52]': np.int64(35), '[ 5 53]': np.int64(35), '[ 5 54]': np.int64(35), '[ 5 55]': np.int64(35), '[ 5 56]': np.int64(35), '[ 5 57]': np.int64(35), '[ 5 58]': np.int64(35), '[ 5 59]': np.int64(35), '[6 0]': np.int64(36), '[6 1]': np.int64(36), '[6 2]': np.int64(36), '[6 3]': np.int64(36), '[6 4]': np.int64(36), '[6 5]': np.int64(36), '[6 6]': np.int64(36), '[6 7]': np.int64(36), '[6 8]': np.int64(36), '[6 9]': np.int64(36), '[ 6 10]': np.int64(37), '[ 6 11]': np.int64(37), '[ 6 12]': np.int64(37), '[ 6 13]': np.int64(37), '[ 6 14]': np.int64(37), '[ 6 15]': np.int64(37), '[ 6 16]': np.int64(37), '[ 6 17]': np.int64(37), '[ 6 18]': np.int64(37), '[ 6 19]': np.int64(37), '[ 6 20]': np.int64(38), '[ 6 21]': np.int64(38), '[ 6 22]': np.int64(38), '[ 6 23]': np.int64(38), '[ 6 24]': np.int64(38), '[ 6 25]': np.int64(38), '[ 6 26]': np.int64(38), '[ 6 27]': np.int64(38), '[ 6 28]': np.int64(38), '[ 6 29]': np.int64(38), '[ 6 30]': np.int64(39), '[ 6 31]': np.int64(39), '[ 6 32]': np.int64(39), '[ 6 33]': np.int64(39), '[ 6 34]': np.int64(39), '[ 6 35]': np.int64(39), '[ 6 36]': np.int64(39), '[ 6 37]': np.int64(39), '[ 6 38]': np.int64(39), '[ 6 39]': np.int64(39), '[ 6 40]': np.int64(40), '[ 6 41]': np.int64(40), '[ 6 42]': np.int64(40), '[ 6 43]': np.int64(40), '[ 6 44]': np.int64(40), '[ 6 45]': np.int64(40), '[ 6 46]': np.int64(40), '[ 6 47]': np.int64(40), '[ 6 48]': np.int64(40), '[ 6 49]': np.int64(40), '[ 6 50]': np.int64(41), '[ 6 51]': np.int64(41), '[ 6 52]': np.int64(41), '[ 6 53]': np.int64(41), '[ 6 54]': np.int64(41), '[ 6 55]': np.int64(41), '[ 6 56]': np.int64(41), '[ 6 57]': np.int64(41), '[ 6 58]': np.int64(41), '[ 6 59]': np.int64(41), '[7 0]': np.int64(42), '[7 1]': np.int64(42), '[7 2]': np.int64(42), '[7 3]': np.int64(42), '[7 4]': np.int64(42), '[7 5]': np.int64(42), '[7 6]': np.int64(42), '[7 7]': np.int64(42), '[7 8]': np.int64(42), '[7 9]': np.int64(42), '[ 7 10]': np.int64(43), '[ 7 11]': np.int64(43), '[ 7 12]': np.int64(43), '[ 7 13]': np.int64(43), '[ 7 14]': np.int64(43), '[ 7 15]': np.int64(43), '[ 7 16]': np.int64(43), '[ 7 17]': np.int64(43), '[ 7 18]': np.int64(43), '[ 7 19]': np.int64(43), '[ 7 20]': np.int64(44), '[ 7 21]': np.int64(44), '[ 7 22]': np.int64(44), '[ 7 23]': np.int64(44), '[ 7 24]': np.int64(44), '[ 7 25]': np.int64(44), '[ 7 26]': np.int64(44), '[ 7 27]': np.int64(44), '[ 7 28]': np.int64(44), '[ 7 29]': np.int64(44), '[ 7 30]': np.int64(45), '[ 7 31]': np.int64(45), '[ 7 32]': np.int64(45), '[ 7 33]': np.int64(45), '[ 7 34]': np.int64(45), '[ 7 35]': np.int64(45), '[ 7 36]': np.int64(45), '[ 7 37]': np.int64(45), '[ 7 38]': np.int64(45), '[ 7 39]': np.int64(45), '[ 7 40]': np.int64(46), '[ 7 41]': np.int64(46), '[ 7 42]': np.int64(46), '[ 7 43]': np.int64(46), '[ 7 44]': np.int64(46), '[ 7 45]': np.int64(46), '[ 7 46]': np.int64(46), '[ 7 47]': np.int64(46), '[ 7 48]': np.int64(46), '[ 7 49]': np.int64(46), '[ 7 50]': np.int64(47), '[ 7 51]': np.int64(47), '[ 7 52]': np.int64(47), '[ 7 53]': np.int64(47), '[ 7 54]': np.int64(47), '[ 7 55]': np.int64(47), '[ 7 56]': np.int64(47), '[ 7 57]': np.int64(47), '[ 7 58]': np.int64(47), '[ 7 59]': np.int64(47), '[8 0]': np.int64(48), '[8 1]': np.int64(48), '[8 2]': np.int64(48), '[8 3]': np.int64(48), '[8 4]': np.int64(48), '[8 5]': np.int64(48), '[8 6]': np.int64(48), '[8 7]': np.int64(48), '[8 8]': np.int64(48), '[8 9]': np.int64(48), '[ 8 10]': np.int64(49), '[ 8 11]': np.int64(49), '[ 8 12]': np.int64(49), '[ 8 13]': np.int64(49), '[ 8 14]': np.int64(49), '[ 8 15]': np.int64(49), '[ 8 16]': np.int64(49), '[ 8 17]': np.int64(49), '[ 8 18]': np.int64(49), '[ 8 19]': np.int64(49), '[ 8 20]': np.int64(50), '[ 8 21]': np.int64(50), '[ 8 22]': np.int64(50), '[ 8 23]': np.int64(50), '[ 8 24]': np.int64(50), '[ 8 25]': np.int64(50), '[ 8 26]': np.int64(50), '[ 8 27]': np.int64(50), '[ 8 28]': np.int64(50), '[ 8 29]': np.int64(50), '[ 8 30]': np.int64(51), '[ 8 31]': np.int64(51), '[ 8 32]': np.int64(51), '[ 8 33]': np.int64(51), '[ 8 34]': np.int64(51), '[ 8 35]': np.int64(51), '[ 8 36]': np.int64(51), '[ 8 37]': np.int64(51), '[ 8 38]': np.int64(51), '[ 8 39]': np.int64(51), '[ 8 40]': np.int64(52), '[ 8 41]': np.int64(52), '[ 8 42]': np.int64(52), '[ 8 43]': np.int64(52), '[ 8 44]': np.int64(52), '[ 8 45]': np.int64(52), '[ 8 46]': np.int64(52), '[ 8 47]': np.int64(52), '[ 8 48]': np.int64(52), '[ 8 49]': np.int64(52), '[ 8 50]': np.int64(53), '[ 8 51]': np.int64(53), '[ 8 52]': np.int64(53), '[ 8 53]': np.int64(53), '[ 8 54]': np.int64(53), '[ 8 55]': np.int64(53), '[ 8 56]': np.int64(53), '[ 8 57]': np.int64(53), '[ 8 58]': np.int64(53), '[ 8 59]': np.int64(53), '[9 0]': np.int64(54), '[9 1]': np.int64(54), '[9 2]': np.int64(54), '[9 3]': np.int64(54), '[9 4]': np.int64(54), '[9 5]': np.int64(54), '[9 6]': np.int64(54), '[9 7]': np.int64(54), '[9 8]': np.int64(54), '[9 9]': np.int64(54), '[ 9 10]': np.int64(55), '[ 9 11]': np.int64(55), '[ 9 12]': np.int64(55), '[ 9 13]': np.int64(55), '[ 9 14]': np.int64(55), '[ 9 15]': np.int64(55), '[ 9 16]': np.int64(55), '[ 9 17]': np.int64(55), '[ 9 18]': np.int64(55), '[ 9 19]': np.int64(55), '[ 9 20]': np.int64(56), '[ 9 21]': np.int64(56), '[ 9 22]': np.int64(56), '[ 9 23]': np.int64(56), '[ 9 24]': np.int64(56), '[ 9 25]': np.int64(56), '[ 9 26]': np.int64(56), '[ 9 27]': np.int64(56), '[ 9 28]': np.int64(56), '[ 9 29]': np.int64(56), '[ 9 30]': np.int64(57), '[ 9 31]': np.int64(57), '[ 9 32]': np.int64(57), '[ 9 33]': np.int64(57), '[ 9 34]': np.int64(57), '[ 9 35]': np.int64(57), '[ 9 36]': np.int64(57), '[ 9 37]': np.int64(57), '[ 9 38]': np.int64(57), '[ 9 39]': np.int64(57), '[ 9 40]': np.int64(58), '[ 9 41]': np.int64(58), '[ 9 42]': np.int64(58), '[ 9 43]': np.int64(58), '[ 9 44]': np.int64(58), '[ 9 45]': np.int64(58), '[ 9 46]': np.int64(58), '[ 9 47]': np.int64(58), '[ 9 48]': np.int64(58), '[ 9 49]': np.int64(58), '[ 9 50]': np.int64(59), '[ 9 51]': np.int64(59), '[ 9 52]': np.int64(59), '[ 9 53]': np.int64(59), '[ 9 54]': np.int64(59), '[ 9 55]': np.int64(59), '[ 9 56]': np.int64(59), '[ 9 57]': np.int64(59), '[ 9 58]': np.int64(59), '[ 9 59]': np.int64(59), '[10  0]': np.int64(60), '[10  1]': np.int64(60), '[10  2]': np.int64(60), '[10  3]': np.int64(60), '[10  4]': np.int64(60), '[10  5]': np.int64(60), '[10  6]': np.int64(60), '[10  7]': np.int64(60), '[10  8]': np.int64(60), '[10  9]': np.int64(60), '[10 10]': np.int64(61), '[10 11]': np.int64(61), '[10 12]': np.int64(61), '[10 13]': np.int64(61), '[10 14]': np.int64(61), '[10 15]': np.int64(61), '[10 16]': np.int64(61), '[10 17]': np.int64(61), '[10 18]': np.int64(61), '[10 19]': np.int64(61), '[10 20]': np.int64(62), '[10 21]': np.int64(62), '[10 22]': np.int64(62), '[10 23]': np.int64(62), '[10 24]': np.int64(62), '[10 25]': np.int64(62), '[10 26]': np.int64(62), '[10 27]': np.int64(62), '[10 28]': np.int64(62), '[10 29]': np.int64(62), '[10 30]': np.int64(63), '[10 31]': np.int64(63), '[10 32]': np.int64(63), '[10 33]': np.int64(63), '[10 34]': np.int64(63), '[10 35]': np.int64(63), '[10 36]': np.int64(63), '[10 37]': np.int64(63), '[10 38]': np.int64(63), '[10 39]': np.int64(63), '[10 40]': np.int64(64), '[10 41]': np.int64(64), '[10 42]': np.int64(64), '[10 43]': np.int64(64), '[10 44]': np.int64(64), '[10 45]': np.int64(64), '[10 46]': np.int64(64), '[10 47]': np.int64(64), '[10 48]': np.int64(64), '[10 49]': np.int64(64), '[10 50]': np.int64(65), '[10 51]': np.int64(65), '[10 52]': np.int64(65), '[10 53]': np.int64(65), '[10 54]': np.int64(65), '[10 55]': np.int64(65), '[10 56]': np.int64(65), '[10 57]': np.int64(65), '[10 58]': np.int64(65), '[10 59]': np.int64(65), '[11  0]': np.int64(66), '[11  1]': np.int64(66), '[11  2]': np.int64(66), '[11  3]': np.int64(66), '[11  4]': np.int64(66), '[11  5]': np.int64(66), '[11  6]': np.int64(66), '[11  7]': np.int64(66), '[11  8]': np.int64(66), '[11  9]': np.int64(66), '[11 10]': np.int64(67), '[11 11]': np.int64(67), '[11 12]': np.int64(67), '[11 13]': np.int64(67), '[11 14]': np.int64(67), '[11 15]': np.int64(67), '[11 16]': np.int64(67), '[11 17]': np.int64(67), '[11 18]': np.int64(67), '[11 19]': np.int64(67), '[11 20]': np.int64(68), '[11 21]': np.int64(68), '[11 22]': np.int64(68), '[11 23]': np.int64(68), '[11 24]': np.int64(68), '[11 25]': np.int64(68), '[11 26]': np.int64(68), '[11 27]': np.int64(68), '[11 28]': np.int64(68), '[11 29]': np.int64(68), '[11 30]': np.int64(69), '[11 31]': np.int64(69), '[11 32]': np.int64(69), '[11 33]': np.int64(69), '[11 34]': np.int64(69), '[11 35]': np.int64(69), '[11 36]': np.int64(69), '[11 37]': np.int64(69), '[11 38]': np.int64(69), '[11 39]': np.int64(69), '[11 40]': np.int64(70), '[11 41]': np.int64(70), '[11 42]': np.int64(70), '[11 43]': np.int64(70), '[11 44]': np.int64(70), '[11 45]': np.int64(70), '[11 46]': np.int64(70), '[11 47]': np.int64(70), '[11 48]': np.int64(70), '[11 49]': np.int64(70), '[11 50]': np.int64(71), '[11 51]': np.int64(71), '[11 52]': np.int64(71), '[11 53]': np.int64(71), '[11 54]': np.int64(71), '[11 55]': np.int64(71), '[11 56]': np.int64(71), '[11 57]': np.int64(71), '[11 58]': np.int64(71), '[11 59]': np.int64(71)}\n"
     ]
    }
   ],
   "source": [
    "labels = np.load(labels_path)\n",
    "\n",
    "def get_cat_labels_10(labels):\n",
    "    new_labels = []\n",
    "    dct = {}\n",
    "    for label in labels:\n",
    "        old = label\n",
    "        label = label[0]* 6 + int((label[1])/10)\n",
    "        new_labels.append(label)\n",
    "        dct[str(old)] = label\n",
    "    print(dct)\n",
    "    return np.array(new_labels)\n",
    "labels = get_cat_labels_10(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "482e8cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test,y_train_full, y_test = train_test_split(\n",
    "    images, labels, test_size=0.1, random_state=35\n",
    ")\n",
    "X_train, X_valid,y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=1/9, random_state=35\n",
    ") # 1/9 x 0.9 = 0.1. train test split shuffles by default\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bce00e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_sense_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    y_pred_class = tf.argmax(y_pred, axis=1)\n",
    "    y_true_float = tf.cast(tf.squeeze(y_true), dtype=tf.float32)\n",
    "    y_pred_float = tf.cast(y_pred_class, dtype=tf.float32)\n",
    "    diff = tf.abs(y_true_float - y_pred_float)\n",
    "    cyclical_diff = tf.minimum(diff, 12.0 - diff)\n",
    "    print(cyclical_diff)\n",
    "    return tf.reduce_mean(cyclical_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3f836073",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pool = keras.layers.MaxPool2D(pool_size=2)\n",
    "lr_scheduler = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,          # halce the learning rate if no improvement\n",
    "    patience=2,          # Wait 2 epochs with no improvement before reducing\n",
    "    min_lr=1e-6          # Set a minimum learning rate at 1e-6\n",
    ")\n",
    "early_stopper = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,          # Wait 5 epochs for improvement before stopping\n",
    "    restore_best_weights=True  # Automatically restore the model weights from the best epoch\n",
    ")\n",
    "# avg_pool = keras.layers.AveragePooling2D(pool_size=2)\n",
    "model = keras.models.Sequential([\n",
    "    keras.Input(shape=(75, 75, 1)),\n",
    "    # Block 1\n",
    "    keras.layers.Conv2D(32, (3,3), activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPooling2D((2,2)), # Output shape: (37, 37, 32)\n",
    "\n",
    "    # Block 2\n",
    "    keras.layers.Conv2D(64, (3,3), activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(64, (3,3), activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPooling2D(2), # Output shape: (18, 18, 64)\n",
    "\n",
    "    # Block 3\n",
    "    keras.layers.Conv2D(128, (3,3), activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(128, (3,3), activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPooling2D(2), # Output shape: (9, 9, 128)\n",
    "\n",
    "    # Block 4\n",
    "    keras.layers.Conv2D(256, (3,3), activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPooling2D(2), # Output shape: (4, 4, 256)\n",
    "\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128, activation=\"leaky_relu\"),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(64, activation=\"leaky_relu\"),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(72, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "metrics=[common_sense_loss,\"Accuracy\"\n",
    "        #   tf.keras.metrics.Precision(), tf.keras.metrics.Recall()\n",
    "          ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e82a6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - Accuracy: 0.9309 - common_sense_loss: 0.0900 - loss: 0.2031 - val_Accuracy: 0.9156 - val_common_sense_loss: 0.1091 - val_loss: 0.2537 - learning_rate: 3.1250e-05\n",
      "Epoch 2/10\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - Accuracy: 0.9324 - common_sense_loss: 0.0492 - loss: 0.1923 - val_Accuracy: 0.9122 - val_common_sense_loss: 0.0735 - val_loss: 0.2550 - learning_rate: 3.1250e-05\n",
      "Epoch 3/10\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - Accuracy: 0.9317 - common_sense_loss: 0.0530 - loss: 0.1989 - val_Accuracy: 0.9100 - val_common_sense_loss: 0.0707 - val_loss: 0.2669 - learning_rate: 3.1250e-05\n",
      "Epoch 4/10\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - Accuracy: 0.9408 - common_sense_loss: 0.0096 - loss: 0.1797 - val_Accuracy: 0.9133 - val_common_sense_loss: 0.0768 - val_loss: 0.2498 - learning_rate: 1.5625e-05\n",
      "Epoch 5/10\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - Accuracy: 0.9401 - common_sense_loss: 0.0856 - loss: 0.1767 - val_Accuracy: 0.9122 - val_common_sense_loss: 0.0800 - val_loss: 0.2646 - learning_rate: 1.5625e-05\n",
      "Epoch 6/10\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - Accuracy: 0.9359 - common_sense_loss: 0.0411 - loss: 0.1909 - val_Accuracy: 0.9094 - val_common_sense_loss: 0.0658 - val_loss: 0.2576 - learning_rate: 1.5625e-05\n",
      "Epoch 7/10\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - Accuracy: 0.9388 - common_sense_loss: 0.0474 - loss: 0.1779 - val_Accuracy: 0.9128 - val_common_sense_loss: 0.0740 - val_loss: 0.2560 - learning_rate: 7.8125e-06\n",
      "Epoch 8/10\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - Accuracy: 0.9360 - common_sense_loss: 0.0549 - loss: 0.1770 - val_Accuracy: 0.9133 - val_common_sense_loss: 0.0521 - val_loss: 0.2532 - learning_rate: 7.8125e-06\n",
      "Epoch 9/10\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - Accuracy: 0.9433 - common_sense_loss: 0.0039 - loss: 0.1681 - val_Accuracy: 0.9128 - val_common_sense_loss: 0.0274 - val_loss: 0.2509 - learning_rate: 3.9063e-06\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Accuracy: 0.9194 - common_sense_loss: 0.1234 - loss: 0.2614\n",
      "Test accuracy: 0.9194444417953491\n",
      "2.20.0\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=10,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=[lr_scheduler, early_stopper]\n",
    "    )\n",
    "#evaluate the model on the test set\n",
    "test_loss,test_csl, test_acc = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', test_acc)\n",
    "#base:0.8420000076293945\n",
    "#leaky: 0.8525000214576721\n",
    "#leaky + L2regularization: 0.8472999930381775\n",
    "#leaky + batch normalization: 0.8978000283241272\n",
    "\n",
    "(print(tf.__version__))\n",
    "#0.9194444417953491\n",
    "# metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "23733489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'[0 0]': np.int64(0), '[0 1]': np.int64(1), '[0 2]': np.int64(2), '[0 3]': np.int64(3), '[0 4]': np.int64(4), '[0 5]': np.int64(5), '[0 6]': np.int64(6), '[0 7]': np.int64(7), '[0 8]': np.int64(8), '[0 9]': np.int64(9), '[ 0 10]': np.int64(10), '[ 0 11]': np.int64(11), '[ 0 12]': np.int64(12), '[ 0 13]': np.int64(13), '[ 0 14]': np.int64(14), '[ 0 15]': np.int64(15), '[ 0 16]': np.int64(16), '[ 0 17]': np.int64(17), '[ 0 18]': np.int64(18), '[ 0 19]': np.int64(19), '[ 0 20]': np.int64(20), '[ 0 21]': np.int64(21), '[ 0 22]': np.int64(22), '[ 0 23]': np.int64(23), '[ 0 24]': np.int64(24), '[ 0 25]': np.int64(25), '[ 0 26]': np.int64(26), '[ 0 27]': np.int64(27), '[ 0 28]': np.int64(28), '[ 0 29]': np.int64(29), '[ 0 30]': np.int64(30), '[ 0 31]': np.int64(31), '[ 0 32]': np.int64(32), '[ 0 33]': np.int64(33), '[ 0 34]': np.int64(34), '[ 0 35]': np.int64(35), '[ 0 36]': np.int64(36), '[ 0 37]': np.int64(37), '[ 0 38]': np.int64(38), '[ 0 39]': np.int64(39), '[ 0 40]': np.int64(40), '[ 0 41]': np.int64(41), '[ 0 42]': np.int64(42), '[ 0 43]': np.int64(43), '[ 0 44]': np.int64(44), '[ 0 45]': np.int64(45), '[ 0 46]': np.int64(46), '[ 0 47]': np.int64(47), '[ 0 48]': np.int64(48), '[ 0 49]': np.int64(49), '[ 0 50]': np.int64(50), '[ 0 51]': np.int64(51), '[ 0 52]': np.int64(52), '[ 0 53]': np.int64(53), '[ 0 54]': np.int64(54), '[ 0 55]': np.int64(55), '[ 0 56]': np.int64(56), '[ 0 57]': np.int64(57), '[ 0 58]': np.int64(58), '[ 0 59]': np.int64(59), '[1 0]': np.int64(60), '[1 1]': np.int64(61), '[1 2]': np.int64(62), '[1 3]': np.int64(63), '[1 4]': np.int64(64), '[1 5]': np.int64(65), '[1 6]': np.int64(66), '[1 7]': np.int64(67), '[1 8]': np.int64(68), '[1 9]': np.int64(69), '[ 1 10]': np.int64(70), '[ 1 11]': np.int64(71), '[ 1 12]': np.int64(72), '[ 1 13]': np.int64(73), '[ 1 14]': np.int64(74), '[ 1 15]': np.int64(75), '[ 1 16]': np.int64(76), '[ 1 17]': np.int64(77), '[ 1 18]': np.int64(78), '[ 1 19]': np.int64(79), '[ 1 20]': np.int64(80), '[ 1 21]': np.int64(81), '[ 1 22]': np.int64(82), '[ 1 23]': np.int64(83), '[ 1 24]': np.int64(84), '[ 1 25]': np.int64(85), '[ 1 26]': np.int64(86), '[ 1 27]': np.int64(87), '[ 1 28]': np.int64(88), '[ 1 29]': np.int64(89), '[ 1 30]': np.int64(90), '[ 1 31]': np.int64(91), '[ 1 32]': np.int64(92), '[ 1 33]': np.int64(93), '[ 1 34]': np.int64(94), '[ 1 35]': np.int64(95), '[ 1 36]': np.int64(96), '[ 1 37]': np.int64(97), '[ 1 38]': np.int64(98), '[ 1 39]': np.int64(99), '[ 1 40]': np.int64(100), '[ 1 41]': np.int64(101), '[ 1 42]': np.int64(102), '[ 1 43]': np.int64(103), '[ 1 44]': np.int64(104), '[ 1 45]': np.int64(105), '[ 1 46]': np.int64(106), '[ 1 47]': np.int64(107), '[ 1 48]': np.int64(108), '[ 1 49]': np.int64(109), '[ 1 50]': np.int64(110), '[ 1 51]': np.int64(111), '[ 1 52]': np.int64(112), '[ 1 53]': np.int64(113), '[ 1 54]': np.int64(114), '[ 1 55]': np.int64(115), '[ 1 56]': np.int64(116), '[ 1 57]': np.int64(117), '[ 1 58]': np.int64(118), '[ 1 59]': np.int64(119), '[2 0]': np.int64(120), '[2 1]': np.int64(121), '[2 2]': np.int64(122), '[2 3]': np.int64(123), '[2 4]': np.int64(124), '[2 5]': np.int64(125), '[2 6]': np.int64(126), '[2 7]': np.int64(127), '[2 8]': np.int64(128), '[2 9]': np.int64(129), '[ 2 10]': np.int64(130), '[ 2 11]': np.int64(131), '[ 2 12]': np.int64(132), '[ 2 13]': np.int64(133), '[ 2 14]': np.int64(134), '[ 2 15]': np.int64(135), '[ 2 16]': np.int64(136), '[ 2 17]': np.int64(137), '[ 2 18]': np.int64(138), '[ 2 19]': np.int64(139), '[ 2 20]': np.int64(140), '[ 2 21]': np.int64(141), '[ 2 22]': np.int64(142), '[ 2 23]': np.int64(143), '[ 2 24]': np.int64(144), '[ 2 25]': np.int64(145), '[ 2 26]': np.int64(146), '[ 2 27]': np.int64(147), '[ 2 28]': np.int64(148), '[ 2 29]': np.int64(149), '[ 2 30]': np.int64(150), '[ 2 31]': np.int64(151), '[ 2 32]': np.int64(152), '[ 2 33]': np.int64(153), '[ 2 34]': np.int64(154), '[ 2 35]': np.int64(155), '[ 2 36]': np.int64(156), '[ 2 37]': np.int64(157), '[ 2 38]': np.int64(158), '[ 2 39]': np.int64(159), '[ 2 40]': np.int64(160), '[ 2 41]': np.int64(161), '[ 2 42]': np.int64(162), '[ 2 43]': np.int64(163), '[ 2 44]': np.int64(164), '[ 2 45]': np.int64(165), '[ 2 46]': np.int64(166), '[ 2 47]': np.int64(167), '[ 2 48]': np.int64(168), '[ 2 49]': np.int64(169), '[ 2 50]': np.int64(170), '[ 2 51]': np.int64(171), '[ 2 52]': np.int64(172), '[ 2 53]': np.int64(173), '[ 2 54]': np.int64(174), '[ 2 55]': np.int64(175), '[ 2 56]': np.int64(176), '[ 2 57]': np.int64(177), '[ 2 58]': np.int64(178), '[ 2 59]': np.int64(179), '[3 0]': np.int64(180), '[3 1]': np.int64(181), '[3 2]': np.int64(182), '[3 3]': np.int64(183), '[3 4]': np.int64(184), '[3 5]': np.int64(185), '[3 6]': np.int64(186), '[3 7]': np.int64(187), '[3 8]': np.int64(188), '[3 9]': np.int64(189), '[ 3 10]': np.int64(190), '[ 3 11]': np.int64(191), '[ 3 12]': np.int64(192), '[ 3 13]': np.int64(193), '[ 3 14]': np.int64(194), '[ 3 15]': np.int64(195), '[ 3 16]': np.int64(196), '[ 3 17]': np.int64(197), '[ 3 18]': np.int64(198), '[ 3 19]': np.int64(199), '[ 3 20]': np.int64(200), '[ 3 21]': np.int64(201), '[ 3 22]': np.int64(202), '[ 3 23]': np.int64(203), '[ 3 24]': np.int64(204), '[ 3 25]': np.int64(205), '[ 3 26]': np.int64(206), '[ 3 27]': np.int64(207), '[ 3 28]': np.int64(208), '[ 3 29]': np.int64(209), '[ 3 30]': np.int64(210), '[ 3 31]': np.int64(211), '[ 3 32]': np.int64(212), '[ 3 33]': np.int64(213), '[ 3 34]': np.int64(214), '[ 3 35]': np.int64(215), '[ 3 36]': np.int64(216), '[ 3 37]': np.int64(217), '[ 3 38]': np.int64(218), '[ 3 39]': np.int64(219), '[ 3 40]': np.int64(220), '[ 3 41]': np.int64(221), '[ 3 42]': np.int64(222), '[ 3 43]': np.int64(223), '[ 3 44]': np.int64(224), '[ 3 45]': np.int64(225), '[ 3 46]': np.int64(226), '[ 3 47]': np.int64(227), '[ 3 48]': np.int64(228), '[ 3 49]': np.int64(229), '[ 3 50]': np.int64(230), '[ 3 51]': np.int64(231), '[ 3 52]': np.int64(232), '[ 3 53]': np.int64(233), '[ 3 54]': np.int64(234), '[ 3 55]': np.int64(235), '[ 3 56]': np.int64(236), '[ 3 57]': np.int64(237), '[ 3 58]': np.int64(238), '[ 3 59]': np.int64(239), '[4 0]': np.int64(240), '[4 1]': np.int64(241), '[4 2]': np.int64(242), '[4 3]': np.int64(243), '[4 4]': np.int64(244), '[4 5]': np.int64(245), '[4 6]': np.int64(246), '[4 7]': np.int64(247), '[4 8]': np.int64(248), '[4 9]': np.int64(249), '[ 4 10]': np.int64(250), '[ 4 11]': np.int64(251), '[ 4 12]': np.int64(252), '[ 4 13]': np.int64(253), '[ 4 14]': np.int64(254), '[ 4 15]': np.int64(255), '[ 4 16]': np.int64(256), '[ 4 17]': np.int64(257), '[ 4 18]': np.int64(258), '[ 4 19]': np.int64(259), '[ 4 20]': np.int64(260), '[ 4 21]': np.int64(261), '[ 4 22]': np.int64(262), '[ 4 23]': np.int64(263), '[ 4 24]': np.int64(264), '[ 4 25]': np.int64(265), '[ 4 26]': np.int64(266), '[ 4 27]': np.int64(267), '[ 4 28]': np.int64(268), '[ 4 29]': np.int64(269), '[ 4 30]': np.int64(270), '[ 4 31]': np.int64(271), '[ 4 32]': np.int64(272), '[ 4 33]': np.int64(273), '[ 4 34]': np.int64(274), '[ 4 35]': np.int64(275), '[ 4 36]': np.int64(276), '[ 4 37]': np.int64(277), '[ 4 38]': np.int64(278), '[ 4 39]': np.int64(279), '[ 4 40]': np.int64(280), '[ 4 41]': np.int64(281), '[ 4 42]': np.int64(282), '[ 4 43]': np.int64(283), '[ 4 44]': np.int64(284), '[ 4 45]': np.int64(285), '[ 4 46]': np.int64(286), '[ 4 47]': np.int64(287), '[ 4 48]': np.int64(288), '[ 4 49]': np.int64(289), '[ 4 50]': np.int64(290), '[ 4 51]': np.int64(291), '[ 4 52]': np.int64(292), '[ 4 53]': np.int64(293), '[ 4 54]': np.int64(294), '[ 4 55]': np.int64(295), '[ 4 56]': np.int64(296), '[ 4 57]': np.int64(297), '[ 4 58]': np.int64(298), '[ 4 59]': np.int64(299), '[5 0]': np.int64(300), '[5 1]': np.int64(301), '[5 2]': np.int64(302), '[5 3]': np.int64(303), '[5 4]': np.int64(304), '[5 5]': np.int64(305), '[5 6]': np.int64(306), '[5 7]': np.int64(307), '[5 8]': np.int64(308), '[5 9]': np.int64(309), '[ 5 10]': np.int64(310), '[ 5 11]': np.int64(311), '[ 5 12]': np.int64(312), '[ 5 13]': np.int64(313), '[ 5 14]': np.int64(314), '[ 5 15]': np.int64(315), '[ 5 16]': np.int64(316), '[ 5 17]': np.int64(317), '[ 5 18]': np.int64(318), '[ 5 19]': np.int64(319), '[ 5 20]': np.int64(320), '[ 5 21]': np.int64(321), '[ 5 22]': np.int64(322), '[ 5 23]': np.int64(323), '[ 5 24]': np.int64(324), '[ 5 25]': np.int64(325), '[ 5 26]': np.int64(326), '[ 5 27]': np.int64(327), '[ 5 28]': np.int64(328), '[ 5 29]': np.int64(329), '[ 5 30]': np.int64(330), '[ 5 31]': np.int64(331), '[ 5 32]': np.int64(332), '[ 5 33]': np.int64(333), '[ 5 34]': np.int64(334), '[ 5 35]': np.int64(335), '[ 5 36]': np.int64(336), '[ 5 37]': np.int64(337), '[ 5 38]': np.int64(338), '[ 5 39]': np.int64(339), '[ 5 40]': np.int64(340), '[ 5 41]': np.int64(341), '[ 5 42]': np.int64(342), '[ 5 43]': np.int64(343), '[ 5 44]': np.int64(344), '[ 5 45]': np.int64(345), '[ 5 46]': np.int64(346), '[ 5 47]': np.int64(347), '[ 5 48]': np.int64(348), '[ 5 49]': np.int64(349), '[ 5 50]': np.int64(350), '[ 5 51]': np.int64(351), '[ 5 52]': np.int64(352), '[ 5 53]': np.int64(353), '[ 5 54]': np.int64(354), '[ 5 55]': np.int64(355), '[ 5 56]': np.int64(356), '[ 5 57]': np.int64(357), '[ 5 58]': np.int64(358), '[ 5 59]': np.int64(359), '[6 0]': np.int64(360), '[6 1]': np.int64(361), '[6 2]': np.int64(362), '[6 3]': np.int64(363), '[6 4]': np.int64(364), '[6 5]': np.int64(365), '[6 6]': np.int64(366), '[6 7]': np.int64(367), '[6 8]': np.int64(368), '[6 9]': np.int64(369), '[ 6 10]': np.int64(370), '[ 6 11]': np.int64(371), '[ 6 12]': np.int64(372), '[ 6 13]': np.int64(373), '[ 6 14]': np.int64(374), '[ 6 15]': np.int64(375), '[ 6 16]': np.int64(376), '[ 6 17]': np.int64(377), '[ 6 18]': np.int64(378), '[ 6 19]': np.int64(379), '[ 6 20]': np.int64(380), '[ 6 21]': np.int64(381), '[ 6 22]': np.int64(382), '[ 6 23]': np.int64(383), '[ 6 24]': np.int64(384), '[ 6 25]': np.int64(385), '[ 6 26]': np.int64(386), '[ 6 27]': np.int64(387), '[ 6 28]': np.int64(388), '[ 6 29]': np.int64(389), '[ 6 30]': np.int64(390), '[ 6 31]': np.int64(391), '[ 6 32]': np.int64(392), '[ 6 33]': np.int64(393), '[ 6 34]': np.int64(394), '[ 6 35]': np.int64(395), '[ 6 36]': np.int64(396), '[ 6 37]': np.int64(397), '[ 6 38]': np.int64(398), '[ 6 39]': np.int64(399), '[ 6 40]': np.int64(400), '[ 6 41]': np.int64(401), '[ 6 42]': np.int64(402), '[ 6 43]': np.int64(403), '[ 6 44]': np.int64(404), '[ 6 45]': np.int64(405), '[ 6 46]': np.int64(406), '[ 6 47]': np.int64(407), '[ 6 48]': np.int64(408), '[ 6 49]': np.int64(409), '[ 6 50]': np.int64(410), '[ 6 51]': np.int64(411), '[ 6 52]': np.int64(412), '[ 6 53]': np.int64(413), '[ 6 54]': np.int64(414), '[ 6 55]': np.int64(415), '[ 6 56]': np.int64(416), '[ 6 57]': np.int64(417), '[ 6 58]': np.int64(418), '[ 6 59]': np.int64(419), '[7 0]': np.int64(420), '[7 1]': np.int64(421), '[7 2]': np.int64(422), '[7 3]': np.int64(423), '[7 4]': np.int64(424), '[7 5]': np.int64(425), '[7 6]': np.int64(426), '[7 7]': np.int64(427), '[7 8]': np.int64(428), '[7 9]': np.int64(429), '[ 7 10]': np.int64(430), '[ 7 11]': np.int64(431), '[ 7 12]': np.int64(432), '[ 7 13]': np.int64(433), '[ 7 14]': np.int64(434), '[ 7 15]': np.int64(435), '[ 7 16]': np.int64(436), '[ 7 17]': np.int64(437), '[ 7 18]': np.int64(438), '[ 7 19]': np.int64(439), '[ 7 20]': np.int64(440), '[ 7 21]': np.int64(441), '[ 7 22]': np.int64(442), '[ 7 23]': np.int64(443), '[ 7 24]': np.int64(444), '[ 7 25]': np.int64(445), '[ 7 26]': np.int64(446), '[ 7 27]': np.int64(447), '[ 7 28]': np.int64(448), '[ 7 29]': np.int64(449), '[ 7 30]': np.int64(450), '[ 7 31]': np.int64(451), '[ 7 32]': np.int64(452), '[ 7 33]': np.int64(453), '[ 7 34]': np.int64(454), '[ 7 35]': np.int64(455), '[ 7 36]': np.int64(456), '[ 7 37]': np.int64(457), '[ 7 38]': np.int64(458), '[ 7 39]': np.int64(459), '[ 7 40]': np.int64(460), '[ 7 41]': np.int64(461), '[ 7 42]': np.int64(462), '[ 7 43]': np.int64(463), '[ 7 44]': np.int64(464), '[ 7 45]': np.int64(465), '[ 7 46]': np.int64(466), '[ 7 47]': np.int64(467), '[ 7 48]': np.int64(468), '[ 7 49]': np.int64(469), '[ 7 50]': np.int64(470), '[ 7 51]': np.int64(471), '[ 7 52]': np.int64(472), '[ 7 53]': np.int64(473), '[ 7 54]': np.int64(474), '[ 7 55]': np.int64(475), '[ 7 56]': np.int64(476), '[ 7 57]': np.int64(477), '[ 7 58]': np.int64(478), '[ 7 59]': np.int64(479), '[8 0]': np.int64(480), '[8 1]': np.int64(481), '[8 2]': np.int64(482), '[8 3]': np.int64(483), '[8 4]': np.int64(484), '[8 5]': np.int64(485), '[8 6]': np.int64(486), '[8 7]': np.int64(487), '[8 8]': np.int64(488), '[8 9]': np.int64(489), '[ 8 10]': np.int64(490), '[ 8 11]': np.int64(491), '[ 8 12]': np.int64(492), '[ 8 13]': np.int64(493), '[ 8 14]': np.int64(494), '[ 8 15]': np.int64(495), '[ 8 16]': np.int64(496), '[ 8 17]': np.int64(497), '[ 8 18]': np.int64(498), '[ 8 19]': np.int64(499), '[ 8 20]': np.int64(500), '[ 8 21]': np.int64(501), '[ 8 22]': np.int64(502), '[ 8 23]': np.int64(503), '[ 8 24]': np.int64(504), '[ 8 25]': np.int64(505), '[ 8 26]': np.int64(506), '[ 8 27]': np.int64(507), '[ 8 28]': np.int64(508), '[ 8 29]': np.int64(509), '[ 8 30]': np.int64(510), '[ 8 31]': np.int64(511), '[ 8 32]': np.int64(512), '[ 8 33]': np.int64(513), '[ 8 34]': np.int64(514), '[ 8 35]': np.int64(515), '[ 8 36]': np.int64(516), '[ 8 37]': np.int64(517), '[ 8 38]': np.int64(518), '[ 8 39]': np.int64(519), '[ 8 40]': np.int64(520), '[ 8 41]': np.int64(521), '[ 8 42]': np.int64(522), '[ 8 43]': np.int64(523), '[ 8 44]': np.int64(524), '[ 8 45]': np.int64(525), '[ 8 46]': np.int64(526), '[ 8 47]': np.int64(527), '[ 8 48]': np.int64(528), '[ 8 49]': np.int64(529), '[ 8 50]': np.int64(530), '[ 8 51]': np.int64(531), '[ 8 52]': np.int64(532), '[ 8 53]': np.int64(533), '[ 8 54]': np.int64(534), '[ 8 55]': np.int64(535), '[ 8 56]': np.int64(536), '[ 8 57]': np.int64(537), '[ 8 58]': np.int64(538), '[ 8 59]': np.int64(539), '[9 0]': np.int64(540), '[9 1]': np.int64(541), '[9 2]': np.int64(542), '[9 3]': np.int64(543), '[9 4]': np.int64(544), '[9 5]': np.int64(545), '[9 6]': np.int64(546), '[9 7]': np.int64(547), '[9 8]': np.int64(548), '[9 9]': np.int64(549), '[ 9 10]': np.int64(550), '[ 9 11]': np.int64(551), '[ 9 12]': np.int64(552), '[ 9 13]': np.int64(553), '[ 9 14]': np.int64(554), '[ 9 15]': np.int64(555), '[ 9 16]': np.int64(556), '[ 9 17]': np.int64(557), '[ 9 18]': np.int64(558), '[ 9 19]': np.int64(559), '[ 9 20]': np.int64(560), '[ 9 21]': np.int64(561), '[ 9 22]': np.int64(562), '[ 9 23]': np.int64(563), '[ 9 24]': np.int64(564), '[ 9 25]': np.int64(565), '[ 9 26]': np.int64(566), '[ 9 27]': np.int64(567), '[ 9 28]': np.int64(568), '[ 9 29]': np.int64(569), '[ 9 30]': np.int64(570), '[ 9 31]': np.int64(571), '[ 9 32]': np.int64(572), '[ 9 33]': np.int64(573), '[ 9 34]': np.int64(574), '[ 9 35]': np.int64(575), '[ 9 36]': np.int64(576), '[ 9 37]': np.int64(577), '[ 9 38]': np.int64(578), '[ 9 39]': np.int64(579), '[ 9 40]': np.int64(580), '[ 9 41]': np.int64(581), '[ 9 42]': np.int64(582), '[ 9 43]': np.int64(583), '[ 9 44]': np.int64(584), '[ 9 45]': np.int64(585), '[ 9 46]': np.int64(586), '[ 9 47]': np.int64(587), '[ 9 48]': np.int64(588), '[ 9 49]': np.int64(589), '[ 9 50]': np.int64(590), '[ 9 51]': np.int64(591), '[ 9 52]': np.int64(592), '[ 9 53]': np.int64(593), '[ 9 54]': np.int64(594), '[ 9 55]': np.int64(595), '[ 9 56]': np.int64(596), '[ 9 57]': np.int64(597), '[ 9 58]': np.int64(598), '[ 9 59]': np.int64(599), '[10  0]': np.int64(600), '[10  1]': np.int64(601), '[10  2]': np.int64(602), '[10  3]': np.int64(603), '[10  4]': np.int64(604), '[10  5]': np.int64(605), '[10  6]': np.int64(606), '[10  7]': np.int64(607), '[10  8]': np.int64(608), '[10  9]': np.int64(609), '[10 10]': np.int64(610), '[10 11]': np.int64(611), '[10 12]': np.int64(612), '[10 13]': np.int64(613), '[10 14]': np.int64(614), '[10 15]': np.int64(615), '[10 16]': np.int64(616), '[10 17]': np.int64(617), '[10 18]': np.int64(618), '[10 19]': np.int64(619), '[10 20]': np.int64(620), '[10 21]': np.int64(621), '[10 22]': np.int64(622), '[10 23]': np.int64(623), '[10 24]': np.int64(624), '[10 25]': np.int64(625), '[10 26]': np.int64(626), '[10 27]': np.int64(627), '[10 28]': np.int64(628), '[10 29]': np.int64(629), '[10 30]': np.int64(630), '[10 31]': np.int64(631), '[10 32]': np.int64(632), '[10 33]': np.int64(633), '[10 34]': np.int64(634), '[10 35]': np.int64(635), '[10 36]': np.int64(636), '[10 37]': np.int64(637), '[10 38]': np.int64(638), '[10 39]': np.int64(639), '[10 40]': np.int64(640), '[10 41]': np.int64(641), '[10 42]': np.int64(642), '[10 43]': np.int64(643), '[10 44]': np.int64(644), '[10 45]': np.int64(645), '[10 46]': np.int64(646), '[10 47]': np.int64(647), '[10 48]': np.int64(648), '[10 49]': np.int64(649), '[10 50]': np.int64(650), '[10 51]': np.int64(651), '[10 52]': np.int64(652), '[10 53]': np.int64(653), '[10 54]': np.int64(654), '[10 55]': np.int64(655), '[10 56]': np.int64(656), '[10 57]': np.int64(657), '[10 58]': np.int64(658), '[10 59]': np.int64(659), '[11  0]': np.int64(660), '[11  1]': np.int64(661), '[11  2]': np.int64(662), '[11  3]': np.int64(663), '[11  4]': np.int64(664), '[11  5]': np.int64(665), '[11  6]': np.int64(666), '[11  7]': np.int64(667), '[11  8]': np.int64(668), '[11  9]': np.int64(669), '[11 10]': np.int64(670), '[11 11]': np.int64(671), '[11 12]': np.int64(672), '[11 13]': np.int64(673), '[11 14]': np.int64(674), '[11 15]': np.int64(675), '[11 16]': np.int64(676), '[11 17]': np.int64(677), '[11 18]': np.int64(678), '[11 19]': np.int64(679), '[11 20]': np.int64(680), '[11 21]': np.int64(681), '[11 22]': np.int64(682), '[11 23]': np.int64(683), '[11 24]': np.int64(684), '[11 25]': np.int64(685), '[11 26]': np.int64(686), '[11 27]': np.int64(687), '[11 28]': np.int64(688), '[11 29]': np.int64(689), '[11 30]': np.int64(690), '[11 31]': np.int64(691), '[11 32]': np.int64(692), '[11 33]': np.int64(693), '[11 34]': np.int64(694), '[11 35]': np.int64(695), '[11 36]': np.int64(696), '[11 37]': np.int64(697), '[11 38]': np.int64(698), '[11 39]': np.int64(699), '[11 40]': np.int64(700), '[11 41]': np.int64(701), '[11 42]': np.int64(702), '[11 43]': np.int64(703), '[11 44]': np.int64(704), '[11 45]': np.int64(705), '[11 46]': np.int64(706), '[11 47]': np.int64(707), '[11 48]': np.int64(708), '[11 49]': np.int64(709), '[11 50]': np.int64(710), '[11 51]': np.int64(711), '[11 52]': np.int64(712), '[11 53]': np.int64(713), '[11 54]': np.int64(714), '[11 55]': np.int64(715), '[11 56]': np.int64(716), '[11 57]': np.int64(717), '[11 58]': np.int64(718), '[11 59]': np.int64(719)}\n"
     ]
    }
   ],
   "source": [
    "labels = np.load(labels_path)\n",
    "def get_cat_labels_10(labels):\n",
    "    new_labels = []\n",
    "    dct = {}\n",
    "    for label in labels:\n",
    "        old = label\n",
    "        label = label[0]* 60 + int((label[1]))\n",
    "        new_labels.append(label)\n",
    "        dct[str(old)] = label\n",
    "    print(dct)\n",
    "    return np.array(new_labels)\n",
    "labels = get_cat_labels_10(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f0724e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 57 587 472 ... 223 268 344]\n"
     ]
    }
   ],
   "source": [
    "X_train_full, X_test,y_train_full, y_test = train_test_split(\n",
    "    images, labels, test_size=0.1, random_state=35\n",
    ")\n",
    "X_train, X_valid,y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=1/9, random_state=35\n",
    ") # 1/9 x 0.9 = 0.1. train test split shuffles by default\n",
    "print(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513c9086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_sense_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    y_pred_class = tf.argmax(y_pred, axis=1)\n",
    "    y_true_float = tf.cast(tf.squeeze(y_true), dtype=tf.float32)\n",
    "    y_pred_float = tf.cast(y_pred_class, dtype=tf.float32)\n",
    "    diff = tf.abs(y_true_float - y_pred_float)\n",
    "    cyclical_diff = tf.minimum(diff, 720.0 - diff)\n",
    "    print(cyclical_diff)\n",
    "    return tf.reduce_mean(cyclical_diff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "17247479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_pool = keras.layers.MaxPool2D(pool_size=2)\n",
    "lr_scheduler = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.1,          # halce the learning rate if no improvement\n",
    "    patience=5,          # Wait 4 epochs with no improvement before reducing\n",
    "    min_lr=1e-9         # Set a minimum learning rate at 1e-6\n",
    ")\n",
    "early_stopper = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,          # Wait 8 epochs for improvement before stopping\n",
    "    restore_best_weights=True  # Automatically restore the model weights from the best epoch\n",
    ")\n",
    "# avg_pool = keras.layers.AveragePooling2D(pool_size=2)\n",
    "model = keras.models.Sequential([\n",
    "    keras.Input(shape=(75, 75, 1)),\n",
    "    # Block 1\n",
    "    keras.layers.Conv2D(32, (3,3), activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPooling2D((2,2)), # Output shape: (37, 37, 32)\n",
    "    keras.layers.Dropout(0.15),\n",
    "    # Block 2\n",
    "    keras.layers.Conv2D(64, (3,3), activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(64, (3,3), activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPooling2D(2), # Output shape: (18, 18, 64)\n",
    "    keras.layers.Dropout(0.15),\n",
    "    # Block 3\n",
    "    keras.layers.Conv2D(128, (3,3), activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(128, (3,3), activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPooling2D(2), # Output shape: (9, 9, 128)\n",
    "    keras.layers.Dropout(0.15),\n",
    "    # Block 4\n",
    "    keras.layers.Conv2D(256, (3,3), activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPooling2D(2), # Output shape: (4, 4, 256)\n",
    "\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(512, activation=\"leaky_relu\"),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(720, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "optimizer=keras.optimizers.SGD(learning_rate=0.0001),\n",
    "metrics=[\"Accuracy\", common_sense_loss\n",
    "        #   tf.keras.metrics.Precision(), tf.keras.metrics.Recall()\n",
    "          ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ab190630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - Accuracy: 0.0018 - common_sense_loss: 180.7997 - loss: 7.6930 - val_Accuracy: 0.0017 - val_common_sense_loss: 181.3591 - val_loss: 6.7426 - learning_rate: 1.0000e-04\n",
      "Epoch 2/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - Accuracy: 9.0278e-04 - common_sense_loss: 180.3764 - loss: 7.2143 - val_Accuracy: 0.0000e+00 - val_common_sense_loss: 181.4065 - val_loss: 6.7131 - learning_rate: 1.0000e-04\n",
      "Epoch 3/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - Accuracy: 0.0012 - common_sense_loss: 180.1556 - loss: 7.0075 - val_Accuracy: 0.0011 - val_common_sense_loss: 181.4947 - val_loss: 6.6875 - learning_rate: 1.0000e-04\n",
      "Epoch 4/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - Accuracy: 0.0019 - common_sense_loss: 180.2813 - loss: 6.9012 - val_Accuracy: 0.0033 - val_common_sense_loss: 181.5918 - val_loss: 6.7030 - learning_rate: 1.0000e-04\n",
      "Epoch 5/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - Accuracy: 0.0017 - common_sense_loss: 180.1073 - loss: 6.8423 - val_Accuracy: 0.0011 - val_common_sense_loss: 181.6025 - val_loss: 6.6786 - learning_rate: 1.0000e-04\n",
      "Epoch 6/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - Accuracy: 0.0012 - common_sense_loss: 180.1256 - loss: 6.8020 - val_Accuracy: 0.0022 - val_common_sense_loss: 181.5332 - val_loss: 6.6684 - learning_rate: 1.0000e-04\n",
      "Epoch 7/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - Accuracy: 0.0013 - common_sense_loss: 180.0498 - loss: 6.7829 - val_Accuracy: 0.0028 - val_common_sense_loss: 181.5420 - val_loss: 6.6678 - learning_rate: 1.0000e-04\n",
      "Epoch 8/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - Accuracy: 0.0016 - common_sense_loss: 180.1696 - loss: 6.7713 - val_Accuracy: 0.0022 - val_common_sense_loss: 181.5421 - val_loss: 6.6577 - learning_rate: 1.0000e-04\n",
      "Epoch 9/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - Accuracy: 0.0019 - common_sense_loss: 180.1861 - loss: 6.7651 - val_Accuracy: 0.0022 - val_common_sense_loss: 181.4432 - val_loss: 6.6504 - learning_rate: 1.0000e-04\n",
      "Epoch 10/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - Accuracy: 0.0013 - common_sense_loss: 180.1477 - loss: 6.7478 - val_Accuracy: 0.0039 - val_common_sense_loss: 181.4378 - val_loss: 6.6459 - learning_rate: 1.0000e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - Accuracy: 0.0016 - common_sense_loss: 180.1106 - loss: 6.7329 - val_Accuracy: 0.0011 - val_common_sense_loss: 181.4782 - val_loss: 6.6477 - learning_rate: 1.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - Accuracy: 0.0013 - common_sense_loss: 180.1887 - loss: 6.7404 - val_Accuracy: 0.0011 - val_common_sense_loss: 181.4704 - val_loss: 6.6420 - learning_rate: 1.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - Accuracy: 0.0016 - common_sense_loss: 180.1665 - loss: 6.7280 - val_Accuracy: 0.0011 - val_common_sense_loss: 181.4483 - val_loss: 6.6396 - learning_rate: 1.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - Accuracy: 0.0017 - common_sense_loss: 180.1334 - loss: 6.7204 - val_Accuracy: 0.0028 - val_common_sense_loss: 181.4263 - val_loss: 6.6655 - learning_rate: 1.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - Accuracy: 0.0013 - common_sense_loss: 180.1802 - loss: 6.7184 - val_Accuracy: 0.0011 - val_common_sense_loss: 181.4923 - val_loss: 6.6401 - learning_rate: 1.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - Accuracy: 0.0017 - common_sense_loss: 180.1947 - loss: 6.7123 - val_Accuracy: 0.0022 - val_common_sense_loss: 181.4632 - val_loss: 6.6327 - learning_rate: 1.0000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - Accuracy: 0.0015 - common_sense_loss: 180.1033 - loss: 6.7125 - val_Accuracy: 0.0017 - val_common_sense_loss: 181.4241 - val_loss: 6.6318 - learning_rate: 1.0000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - Accuracy: 0.0011 - common_sense_loss: 180.1967 - loss: 6.7078 - val_Accuracy: 0.0022 - val_common_sense_loss: 181.4316 - val_loss: 6.6356 - learning_rate: 1.0000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - Accuracy: 0.0010 - common_sense_loss: 180.1645 - loss: 6.7136 - val_Accuracy: 0.0017 - val_common_sense_loss: 181.4234 - val_loss: 6.6298 - learning_rate: 1.0000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - Accuracy: 0.0012 - common_sense_loss: 180.1494 - loss: 6.7013 - val_Accuracy: 0.0022 - val_common_sense_loss: 181.3962 - val_loss: 6.6326 - learning_rate: 1.0000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - Accuracy: 0.0013 - common_sense_loss: 180.1093 - loss: 6.6983 - val_Accuracy: 0.0011 - val_common_sense_loss: 181.4341 - val_loss: 6.6291 - learning_rate: 1.0000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - Accuracy: 0.0012 - common_sense_loss: 180.1298 - loss: 6.6904 - val_Accuracy: 0.0022 - val_common_sense_loss: 181.3943 - val_loss: 6.6252 - learning_rate: 1.0000e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - Accuracy: 0.0010 - common_sense_loss: 180.0973 - loss: 6.6909 - val_Accuracy: 0.0017 - val_common_sense_loss: 181.4088 - val_loss: 6.6252 - learning_rate: 1.0000e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - Accuracy: 0.0017 - common_sense_loss: 180.1610 - loss: 6.6919 - val_Accuracy: 0.0011 - val_common_sense_loss: 181.4287 - val_loss: 6.6269 - learning_rate: 1.0000e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - Accuracy: 0.0017 - common_sense_loss: 180.0994 - loss: 6.6856 - val_Accuracy: 0.0017 - val_common_sense_loss: 181.4067 - val_loss: 6.6259 - learning_rate: 1.0000e-04\n",
      "Epoch 26/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - Accuracy: 0.0014 - common_sense_loss: 180.0975 - loss: 6.6769 - val_Accuracy: 0.0022 - val_common_sense_loss: 181.4126 - val_loss: 6.6252 - learning_rate: 1.0000e-05\n",
      "Epoch 27/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - Accuracy: 0.0011 - common_sense_loss: 180.2129 - loss: 6.6878 - val_Accuracy: 0.0017 - val_common_sense_loss: 181.4191 - val_loss: 6.6256 - learning_rate: 1.0000e-05\n",
      "Epoch 28/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - Accuracy: 0.0022 - common_sense_loss: 180.1056 - loss: 6.6789 - val_Accuracy: 0.0017 - val_common_sense_loss: 181.4182 - val_loss: 6.6258 - learning_rate: 1.0000e-05\n",
      "Epoch 29/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - Accuracy: 0.0019 - common_sense_loss: 180.1409 - loss: 6.6794 - val_Accuracy: 0.0017 - val_common_sense_loss: 181.4142 - val_loss: 6.6256 - learning_rate: 1.0000e-06\n",
      "Epoch 30/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - Accuracy: 0.0013 - common_sense_loss: 180.0930 - loss: 6.6843 - val_Accuracy: 0.0017 - val_common_sense_loss: 181.4146 - val_loss: 6.6256 - learning_rate: 1.0000e-06\n",
      "Epoch 31/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - Accuracy: 0.0016 - common_sense_loss: 180.0857 - loss: 6.6805 - val_Accuracy: 0.0017 - val_common_sense_loss: 181.4148 - val_loss: 6.6257 - learning_rate: 1.0000e-06\n",
      "Epoch 32/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - Accuracy: 0.0022 - common_sense_loss: 180.0861 - loss: 6.6843 - val_Accuracy: 0.0017 - val_common_sense_loss: 181.4144 - val_loss: 6.6256 - learning_rate: 1.0000e-07\n",
      "Epoch 33/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - Accuracy: 0.0015 - common_sense_loss: 180.1240 - loss: 6.6816 - val_Accuracy: 0.0017 - val_common_sense_loss: 181.4143 - val_loss: 6.6257 - learning_rate: 1.0000e-07\n",
      "Epoch 34/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - Accuracy: 0.0015 - common_sense_loss: 180.1287 - loss: 6.6846 - val_Accuracy: 0.0017 - val_common_sense_loss: 181.4146 - val_loss: 6.6257 - learning_rate: 1.0000e-07\n",
      "Epoch 35/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - Accuracy: 0.0020 - common_sense_loss: 180.1260 - loss: 6.6841 - val_Accuracy: 0.0017 - val_common_sense_loss: 181.4148 - val_loss: 6.6255 - learning_rate: 1.0000e-08\n",
      "Epoch 36/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - Accuracy: 0.0017 - common_sense_loss: 180.1362 - loss: 6.6862 - val_Accuracy: 0.0017 - val_common_sense_loss: 181.4139 - val_loss: 6.6255 - learning_rate: 1.0000e-08\n",
      "Epoch 37/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - Accuracy: 0.0014 - common_sense_loss: 180.0792 - loss: 6.6844 - val_Accuracy: 0.0017 - val_common_sense_loss: 181.4139 - val_loss: 6.6257 - learning_rate: 1.0000e-08\n",
      "Epoch 38/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - Accuracy: 0.0017 - common_sense_loss: 180.1508 - loss: 6.6797 - val_Accuracy: 0.0017 - val_common_sense_loss: 181.4145 - val_loss: 6.6258 - learning_rate: 1.0000e-09\n",
      "Epoch 39/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - Accuracy: 0.0015 - common_sense_loss: 180.1608 - loss: 6.6890 - val_Accuracy: 0.0017 - val_common_sense_loss: 181.4146 - val_loss: 6.6256 - learning_rate: 1.0000e-09\n",
      "Epoch 40/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - Accuracy: 0.0013 - common_sense_loss: 180.0825 - loss: 6.6833 - val_Accuracy: 0.0017 - val_common_sense_loss: 181.4146 - val_loss: 6.6256 - learning_rate: 1.0000e-09\n",
      "Epoch 41/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - Accuracy: 0.0012 - common_sense_loss: 180.0788 - loss: 6.6792 - val_Accuracy: 0.0017 - val_common_sense_loss: 181.4141 - val_loss: 6.6256 - learning_rate: 1.0000e-10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - Accuracy: 0.0017 - common_sense_loss: 176.2004 - loss: 6.6287 \n",
      "Test accuracy: 176.2003631591797\n",
      "2.20.0\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=60,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=[lr_scheduler, early_stopper]\n",
    "    )\n",
    "#evaluate the model on the test set\n",
    "test_loss,test_csl, test_acc = model.evaluate(X_test, y_test)\n",
    "\n",
    "print('Test accuracy:', test_acc)\n",
    "(print(tf.__version__))\n",
    "#0.9194444417953491\n",
    "# metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dbfb4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18000, 2)\n"
     ]
    }
   ],
   "source": [
    "#feature prep for dual head\n",
    "\n",
    "labels = np.load(labels_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99045e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0 57]\n",
      " [ 9 47]\n",
      " [ 7 52]\n",
      " ...\n",
      " [ 3 43]\n",
      " [ 4 28]\n",
      " [ 5 44]]\n"
     ]
    }
   ],
   "source": [
    "X_train_full, X_test,y_train_full, y_test = train_test_split(\n",
    "    images, labels, test_size=0.1, random_state=35\n",
    ")\n",
    "X_train, X_valid,y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=1/9, random_state=35\n",
    ") # 1/9 x 0.9 = 0.1. train test split shuffles by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "9f317cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_hours = y_train[:, 0]\n",
    "y_train_minutes = y_train[:, 1]\n",
    "y_valid_hours = y_valid[:, 0]\n",
    "y_valid_minutes = y_valid[:, 1]\n",
    "y_test_hours = y_test[:, 0]\n",
    "y_test_minutes = y_test[:, 1]\n",
    "\n",
    "#one-hot encoding the labels\n",
    "y_train_hours_enc = keras.utils.to_categorical(y_train_hours, num_classes=12)\n",
    "y_train_minutes_enc = y_train_minutes\n",
    "y_valid_hours_enc = keras.utils.to_categorical(y_valid_hours, num_classes=12)\n",
    "y_valid_minutes_enc = y_valid_minutes\n",
    "y_test_hours_enc = keras.utils.to_categorical(y_test_hours, num_classes=12)\n",
    "y_test_minutes_enc = y_test_minutes\n",
    "y_train_formatted = {\n",
    "    \"hour_output\": y_train_hours_enc,\n",
    "    \"minute_output\": y_train_minutes_enc\n",
    "}\n",
    "\n",
    "y_valid_formatted = {\n",
    "    \"hour_output\": y_valid_hours_enc,\n",
    "    \"minute_output\": y_valid_minutes_enc\n",
    "}\n",
    "y_train_formatted = {\n",
    "    \"hour_output\": y_train_hours_enc,\n",
    "    \"minute_output\": y_train_minutes_enc\n",
    "}\n",
    "\n",
    "y_valid_formatted = {\n",
    "    \"hour_output\": y_valid_hours_enc,\n",
    "    \"minute_output\": y_valid_minutes_enc\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb60277",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "98e0b9a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_68\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_68\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_image         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_414 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │ input_image[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_414[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_315   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_282         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_31… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_415 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │ dropout_282[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_415[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_416 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_416[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_316   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_283         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_31… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_417 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ dropout_283[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_417[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_418 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_418[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_317   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_284         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_31… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_419 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │ dropout_284[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_419[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_318   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_68          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_31… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_192 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,097,664</span> │ flatten_68[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_285         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_192[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_193 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,832</span> │ dropout_285[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_194 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │ dropout_285[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_286         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_193[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_287         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_194[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ hour_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">780</span> │ dropout_286[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ minute_output       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dropout_287[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_image         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m1\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_414 (\u001b[38;5;33mConv2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m75\u001b[0m,    │        \u001b[38;5;34m320\u001b[0m │ input_image[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m75\u001b[0m,    │        \u001b[38;5;34m128\u001b[0m │ conv2d_414[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_315   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m37\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_282         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m37\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_31… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_415 (\u001b[38;5;33mConv2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m37\u001b[0m,    │     \u001b[38;5;34m18,496\u001b[0m │ dropout_282[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m37\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_415[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_416 (\u001b[38;5;33mConv2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m37\u001b[0m,    │     \u001b[38;5;34m36,928\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m37\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_416[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_316   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m18\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_283         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m18\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_31… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_417 (\u001b[38;5;33mConv2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m18\u001b[0m,    │     \u001b[38;5;34m73,856\u001b[0m │ dropout_283[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m18\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_417[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_418 (\u001b[38;5;33mConv2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m18\u001b[0m,    │    \u001b[38;5;34m147,584\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m18\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_418[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_317   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m128\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_284         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m128\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_31… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_419 (\u001b[38;5;33mConv2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m256\u001b[0m) │    \u001b[38;5;34m295,168\u001b[0m │ dropout_284[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m256\u001b[0m) │      \u001b[38;5;34m1,024\u001b[0m │ conv2d_419[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_318   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_68          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_31… │\n",
       "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_192 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │  \u001b[38;5;34m2,097,664\u001b[0m │ flatten_68[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_285         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_192[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_193 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m32,832\u001b[0m │ dropout_285[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_194 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m65,664\u001b[0m │ dropout_285[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_286         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_193[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_287         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_194[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ hour_output (\u001b[38;5;33mDense\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)        │        \u001b[38;5;34m780\u001b[0m │ dropout_286[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ minute_output       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m129\u001b[0m │ dropout_287[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,772,109</span> (10.57 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,772,109\u001b[0m (10.57 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,770,765</span> (10.57 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,770,765\u001b[0m (10.57 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,344</span> (5.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,344\u001b[0m (5.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(75, 75, 1), name=\"input_image\")\n",
    "x = keras.layers.Conv2D(32, (3,3), activation=\"relu\", padding=\"same\")(inputs)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.MaxPooling2D((2,2))(x)\n",
    "x = keras.layers.Dropout(0.15)(x)\n",
    "\n",
    "x = keras.layers.Conv2D(64, (3,3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Conv2D(64, (3,3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.MaxPooling2D(2)(x)\n",
    "x = keras.layers.Dropout(0.15)(x)\n",
    "\n",
    "x = keras.layers.Conv2D(128, (3,3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Conv2D(128, (3,3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.MaxPooling2D(2)(x)\n",
    "x = keras.layers.Dropout(0.15)(x)\n",
    "\n",
    "x = keras.layers.Conv2D(256, (3,3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.MaxPooling2D(2)(x)\n",
    "\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(512, activation=\"leaky_relu\")(x)\n",
    "shared_features = keras.layers.Dropout(0.5)(x)\n",
    "hour_branch = keras.layers.Dense(64, activation=\"leaky_relu\")(shared_features)\n",
    "hour_branch = keras.layers.Dropout(0.5)(hour_branch)\n",
    "hour_output = keras.layers.Dense(12, activation=\"softmax\", name=\"hour_output\")(hour_branch)\n",
    "minute_branch = keras.layers.Dense(128, activation=\"leaky_relu\")(shared_features)\n",
    "minute_branch = keras.layers.Dropout(0.5)(minute_branch)\n",
    "minute_output = keras.layers.Dense(1, activation=\"linear\", name=\"minute_output\")(minute_branch)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=[hour_output, minute_output])\n",
    "minute_loss_weight = 0.005 #mse is a lot higher than crossentropy.\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss={\n",
    "        \"hour_output\": \"categorical_crossentropy\",\n",
    "        \"minute_output\": \"mean_squared_error\"\n",
    "    },\n",
    "    loss_weights={\n",
    "        \"hour_output\": 1,\n",
    "        \"minute_output\": minute_loss_weight\n",
    "    },\n",
    "    metrics={\n",
    "        \"hour_output\": \"accuracy\",\n",
    "        \"minute_output\": \"mean_absolute_error\",\n",
    "    }\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "1426175d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - hour_output_accuracy: 0.8589 - hour_output_loss: 0.3679 - loss: 0.6612 - minute_output_loss: 58.6716 - minute_output_mean_absolute_error: 5.6138 - val_hour_output_accuracy: 0.9183 - val_hour_output_loss: 0.2210 - val_loss: 0.4366 - val_minute_output_loss: 42.3026 - val_minute_output_mean_absolute_error: 4.2366 - learning_rate: 1.0000e-04\n",
      "Epoch 2/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - hour_output_accuracy: 0.8716 - hour_output_loss: 0.3297 - loss: 0.6128 - minute_output_loss: 56.6232 - minute_output_mean_absolute_error: 5.5364 - val_hour_output_accuracy: 0.8894 - val_hour_output_loss: 0.2821 - val_loss: 0.5237 - val_minute_output_loss: 47.5338 - val_minute_output_mean_absolute_error: 4.8370 - learning_rate: 1.0000e-04\n",
      "Epoch 3/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - hour_output_accuracy: 0.8827 - hour_output_loss: 0.3124 - loss: 0.5894 - minute_output_loss: 55.4113 - minute_output_mean_absolute_error: 5.4749 - val_hour_output_accuracy: 0.8617 - val_hour_output_loss: 0.3627 - val_loss: 0.7168 - val_minute_output_loss: 69.9098 - val_minute_output_mean_absolute_error: 6.2200 - learning_rate: 1.0000e-04\n",
      "Epoch 4/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - hour_output_accuracy: 0.8862 - hour_output_loss: 0.2926 - loss: 0.5637 - minute_output_loss: 54.2234 - minute_output_mean_absolute_error: 5.3953 - val_hour_output_accuracy: 0.9378 - val_hour_output_loss: 0.1712 - val_loss: 0.3907 - val_minute_output_loss: 43.2081 - val_minute_output_mean_absolute_error: 4.7385 - learning_rate: 1.0000e-04\n",
      "Epoch 5/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - hour_output_accuracy: 0.8869 - hour_output_loss: 0.2871 - loss: 0.5541 - minute_output_loss: 53.3890 - minute_output_mean_absolute_error: 5.3817 - val_hour_output_accuracy: 0.9000 - val_hour_output_loss: 0.2734 - val_loss: 0.5901 - val_minute_output_loss: 62.3385 - val_minute_output_mean_absolute_error: 6.0542 - learning_rate: 1.0000e-04\n",
      "Epoch 6/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - hour_output_accuracy: 0.9043 - hour_output_loss: 0.2614 - loss: 0.5092 - minute_output_loss: 49.5474 - minute_output_mean_absolute_error: 5.2056 - val_hour_output_accuracy: 0.9200 - val_hour_output_loss: 0.2145 - val_loss: 0.4461 - val_minute_output_loss: 45.5829 - val_minute_output_mean_absolute_error: 4.9291 - learning_rate: 1.0000e-04\n",
      "Epoch 7/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - hour_output_accuracy: 0.9027 - hour_output_loss: 0.2616 - loss: 0.5144 - minute_output_loss: 50.5630 - minute_output_mean_absolute_error: 5.2355 - val_hour_output_accuracy: 0.9056 - val_hour_output_loss: 0.2570 - val_loss: 0.4974 - val_minute_output_loss: 47.4820 - val_minute_output_mean_absolute_error: 4.6428 - learning_rate: 1.0000e-04\n",
      "Epoch 8/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - hour_output_accuracy: 0.9102 - hour_output_loss: 0.2481 - loss: 0.4884 - minute_output_loss: 48.0597 - minute_output_mean_absolute_error: 5.1040 - val_hour_output_accuracy: 0.8822 - val_hour_output_loss: 0.3220 - val_loss: 0.6125 - val_minute_output_loss: 57.3540 - val_minute_output_mean_absolute_error: 5.4448 - learning_rate: 1.0000e-04\n",
      "Epoch 9/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - hour_output_accuracy: 0.9244 - hour_output_loss: 0.2048 - loss: 0.4252 - minute_output_loss: 44.0923 - minute_output_mean_absolute_error: 4.9545 - val_hour_output_accuracy: 0.9644 - val_hour_output_loss: 0.1077 - val_loss: 0.2905 - val_minute_output_loss: 35.9919 - val_minute_output_mean_absolute_error: 4.0778 - learning_rate: 1.0000e-05\n",
      "Epoch 10/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - hour_output_accuracy: 0.9370 - hour_output_loss: 0.1781 - loss: 0.3908 - minute_output_loss: 42.5450 - minute_output_mean_absolute_error: 4.8508 - val_hour_output_accuracy: 0.9606 - val_hour_output_loss: 0.1154 - val_loss: 0.3050 - val_minute_output_loss: 37.3469 - val_minute_output_mean_absolute_error: 4.2188 - learning_rate: 1.0000e-05\n",
      "Epoch 11/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - hour_output_accuracy: 0.9388 - hour_output_loss: 0.1709 - loss: 0.3839 - minute_output_loss: 42.5977 - minute_output_mean_absolute_error: 4.8257 - val_hour_output_accuracy: 0.9644 - val_hour_output_loss: 0.1068 - val_loss: 0.2979 - val_minute_output_loss: 37.6795 - val_minute_output_mean_absolute_error: 4.3189 - learning_rate: 1.0000e-05\n",
      "Epoch 12/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - hour_output_accuracy: 0.9403 - hour_output_loss: 0.1662 - loss: 0.3774 - minute_output_loss: 42.2370 - minute_output_mean_absolute_error: 4.8656 - val_hour_output_accuracy: 0.9667 - val_hour_output_loss: 0.1123 - val_loss: 0.2931 - val_minute_output_loss: 35.6253 - val_minute_output_mean_absolute_error: 4.0975 - learning_rate: 1.0000e-05\n",
      "Epoch 13/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - hour_output_accuracy: 0.9383 - hour_output_loss: 0.1674 - loss: 0.3779 - minute_output_loss: 42.1079 - minute_output_mean_absolute_error: 4.7959 - val_hour_output_accuracy: 0.9644 - val_hour_output_loss: 0.1021 - val_loss: 0.2813 - val_minute_output_loss: 35.3080 - val_minute_output_mean_absolute_error: 4.1389 - learning_rate: 1.0000e-05\n",
      "Epoch 14/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - hour_output_accuracy: 0.9420 - hour_output_loss: 0.1640 - loss: 0.3704 - minute_output_loss: 41.2749 - minute_output_mean_absolute_error: 4.7808 - val_hour_output_accuracy: 0.9561 - val_hour_output_loss: 0.1228 - val_loss: 0.3154 - val_minute_output_loss: 37.9809 - val_minute_output_mean_absolute_error: 4.3499 - learning_rate: 1.0000e-05\n",
      "Epoch 15/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - hour_output_accuracy: 0.9479 - hour_output_loss: 0.1530 - loss: 0.3610 - minute_output_loss: 41.6001 - minute_output_mean_absolute_error: 4.8045 - val_hour_output_accuracy: 0.9594 - val_hour_output_loss: 0.1092 - val_loss: 0.3000 - val_minute_output_loss: 37.6063 - val_minute_output_mean_absolute_error: 4.3408 - learning_rate: 1.0000e-05\n",
      "Epoch 16/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - hour_output_accuracy: 0.9456 - hour_output_loss: 0.1522 - loss: 0.3560 - minute_output_loss: 40.7611 - minute_output_mean_absolute_error: 4.7498 - val_hour_output_accuracy: 0.9650 - val_hour_output_loss: 0.1019 - val_loss: 0.2801 - val_minute_output_loss: 35.0965 - val_minute_output_mean_absolute_error: 4.0437 - learning_rate: 1.0000e-05\n",
      "Epoch 17/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - hour_output_accuracy: 0.9447 - hour_output_loss: 0.1543 - loss: 0.3583 - minute_output_loss: 40.7929 - minute_output_mean_absolute_error: 4.7708 - val_hour_output_accuracy: 0.9617 - val_hour_output_loss: 0.1091 - val_loss: 0.2978 - val_minute_output_loss: 37.1850 - val_minute_output_mean_absolute_error: 4.3065 - learning_rate: 1.0000e-05\n",
      "Epoch 18/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - hour_output_accuracy: 0.9469 - hour_output_loss: 0.1483 - loss: 0.3451 - minute_output_loss: 39.3741 - minute_output_mean_absolute_error: 4.7069 - val_hour_output_accuracy: 0.9578 - val_hour_output_loss: 0.1149 - val_loss: 0.3054 - val_minute_output_loss: 37.5358 - val_minute_output_mean_absolute_error: 4.2755 - learning_rate: 1.0000e-05\n",
      "Epoch 19/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - hour_output_accuracy: 0.9495 - hour_output_loss: 0.1452 - loss: 0.3495 - minute_output_loss: 40.8590 - minute_output_mean_absolute_error: 4.7970 - val_hour_output_accuracy: 0.9606 - val_hour_output_loss: 0.1122 - val_loss: 0.3008 - val_minute_output_loss: 37.1642 - val_minute_output_mean_absolute_error: 4.1537 - learning_rate: 1.0000e-05\n",
      "Epoch 20/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - hour_output_accuracy: 0.9496 - hour_output_loss: 0.1457 - loss: 0.3488 - minute_output_loss: 40.6227 - minute_output_mean_absolute_error: 4.7353 - val_hour_output_accuracy: 0.9594 - val_hour_output_loss: 0.1177 - val_loss: 0.3099 - val_minute_output_loss: 37.8651 - val_minute_output_mean_absolute_error: 4.2126 - learning_rate: 1.0000e-05\n",
      "Epoch 21/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - hour_output_accuracy: 0.9500 - hour_output_loss: 0.1446 - loss: 0.3504 - minute_output_loss: 41.1517 - minute_output_mean_absolute_error: 4.7655 - val_hour_output_accuracy: 0.9633 - val_hour_output_loss: 0.1087 - val_loss: 0.2927 - val_minute_output_loss: 36.2446 - val_minute_output_mean_absolute_error: 4.1393 - learning_rate: 1.0000e-06\n",
      "Epoch 22/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - hour_output_accuracy: 0.9478 - hour_output_loss: 0.1421 - loss: 0.3353 - minute_output_loss: 38.6230 - minute_output_mean_absolute_error: 4.6593 - val_hour_output_accuracy: 0.9639 - val_hour_output_loss: 0.1070 - val_loss: 0.2849 - val_minute_output_loss: 35.0312 - val_minute_output_mean_absolute_error: 4.0446 - learning_rate: 1.0000e-06\n",
      "Epoch 23/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - hour_output_accuracy: 0.9517 - hour_output_loss: 0.1390 - loss: 0.3363 - minute_output_loss: 39.4657 - minute_output_mean_absolute_error: 4.6849 - val_hour_output_accuracy: 0.9622 - val_hour_output_loss: 0.1086 - val_loss: 0.2864 - val_minute_output_loss: 35.0286 - val_minute_output_mean_absolute_error: 4.0589 - learning_rate: 1.0000e-06\n",
      "Epoch 24/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - hour_output_accuracy: 0.9528 - hour_output_loss: 0.1355 - loss: 0.3302 - minute_output_loss: 38.9501 - minute_output_mean_absolute_error: 4.6463 - val_hour_output_accuracy: 0.9633 - val_hour_output_loss: 0.1069 - val_loss: 0.2852 - val_minute_output_loss: 35.1263 - val_minute_output_mean_absolute_error: 4.0778 - learning_rate: 1.0000e-06\n",
      "Epoch 25/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - hour_output_accuracy: 0.9512 - hour_output_loss: 0.1369 - loss: 0.3369 - minute_output_loss: 40.0087 - minute_output_mean_absolute_error: 4.6994 - val_hour_output_accuracy: 0.9628 - val_hour_output_loss: 0.1075 - val_loss: 0.2877 - val_minute_output_loss: 35.4891 - val_minute_output_mean_absolute_error: 4.1014 - learning_rate: 1.0000e-07\n",
      "Epoch 26/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - hour_output_accuracy: 0.9498 - hour_output_loss: 0.1483 - loss: 0.3506 - minute_output_loss: 40.4549 - minute_output_mean_absolute_error: 4.7324 - val_hour_output_accuracy: 0.9628 - val_hour_output_loss: 0.1072 - val_loss: 0.2870 - val_minute_output_loss: 35.4183 - val_minute_output_mean_absolute_error: 4.0893 - learning_rate: 1.0000e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x747d07811510>"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "lr_scheduler = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.10,          # halce the learning rate if no improvement\n",
    "    patience=4,          # Wait 4 epochs with no improvement before reducing\n",
    "    min_lr=1e-9         # Set a minimum learning rate at 1e-6\n",
    ")\n",
    "early_stopper = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=8,          # Wait 8 epochs for improvement before stopping\n",
    "    restore_best_weights=True  # Automatically restore the model weights from the best epoch\n",
    ")\n",
    "model.fit(\n",
    "    X_train, y_train_formatted,\n",
    "    epochs=60,\n",
    "    validation_data=(X_valid, y_valid_formatted),\n",
    "    callbacks=[lr_scheduler, early_stopper]\n",
    "    )\n",
    "# K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "ceefd63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_sense_loss(y_true, y_pred):\n",
    "\n",
    "        y_true_hour = np.argmax(y_true[\"hour_output\"], axis=1)\n",
    "        y_true_minute = np.array(y_true[\"minute_output\"], dtype=float)\n",
    "        y_pred_hour = np.argmax(y_pred[0], axis=1)\n",
    "        y_pred_minute = y_pred[1].squeeze()\n",
    "        y_true_total_minutes = y_true_hour * 60 + y_true_minute\n",
    "        y_pred_total_minutes = y_pred_hour * 60 + y_pred_minute\n",
    "        diff = y_true_total_minutes - y_pred_total_minutes\n",
    "        abs_diff = tf.abs(diff)\n",
    "\n",
    "\n",
    "        cyclical_error = tf.minimum(abs_diff, 720.0 - abs_diff)\n",
    "\n",
    "        return cyclical_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571341f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - hour_output_accuracy: 0.9711 - hour_output_loss: 0.0992 - loss: 0.2942 - minute_output_loss: 38.4920 - minute_output_mean_absolute_error: 4.0071\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "[array([[6.6411525e-07, 1.4670831e-08, 7.9728916e-06, ..., 7.8694655e-12,\n",
      "        7.0172508e-09, 1.5302958e-06],\n",
      "       [3.2581678e-16, 1.1008986e-18, 1.2715607e-20, ..., 6.3151143e-02,\n",
      "        9.3684882e-01, 1.4551491e-08],\n",
      "       [8.7864156e-04, 9.9865305e-01, 4.6823893e-04, ..., 5.0802844e-18,\n",
      "        1.8039712e-13, 5.5778993e-10],\n",
      "       ...,\n",
      "       [1.2183864e-11, 1.2733003e-03, 9.9713576e-01, ..., 6.1500063e-21,\n",
      "        1.4436660e-19, 2.2348427e-19],\n",
      "       [6.2379233e-15, 7.2343755e-16, 5.9267478e-14, ..., 2.8021548e-15,\n",
      "        4.6440737e-15, 3.8109283e-14],\n",
      "       [9.4759143e-16, 1.2355712e-16, 3.0967093e-11, ..., 4.2677498e-20,\n",
      "        4.2906731e-18, 3.1026256e-16]], shape=(1800, 12), dtype=float32), array([[26.36074  ],\n",
      "       [ 7.9434767],\n",
      "       [51.615124 ],\n",
      "       ...,\n",
      "       [36.727383 ],\n",
      "       [17.729887 ],\n",
      "       [30.442673 ]], shape=(1800, 1), dtype=float32)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(5.15378174846371)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_minutes_enc = np.array(y_test_minutes, dtype=float)\n",
    "model.evaluate(X_test, {\n",
    "    \"hour_output\": y_test_hours_enc,\n",
    "    \"minute_output\": y_test_minutes_enc\n",
    "})\n",
    "y_test_formatted = {\n",
    "    \"hour_output\": y_test_hours_enc,\n",
    "    \"minute_output\": y_test_minutes_enc\n",
    "}\n",
    "y_pred_list = model.predict(X_test)\n",
    "\n",
    "np.mean((common_sense_loss(y_test_formatted, y_pred_list)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dba7b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_52\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_52\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_image         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_318 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │ input_image[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_318[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_251   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_186         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_25… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_319 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │ dropout_186[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_319[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_320 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_320[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_252   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_187         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_25… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_321 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ dropout_187[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_321[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_322 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_322[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_253   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_188         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_25… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_323 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │ dropout_188[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_323[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_254   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_52          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_25… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_144 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,097,664</span> │ flatten_52[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_189         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_144[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_145 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,832</span> │ dropout_189[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_146 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │ dropout_189[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_190         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_145[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_191         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_146[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ hour_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">780</span> │ dropout_190[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ minute_output       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,740</span> │ dropout_191[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_image         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m1\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_318 (\u001b[38;5;33mConv2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m75\u001b[0m,    │        \u001b[38;5;34m320\u001b[0m │ input_image[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m75\u001b[0m,    │        \u001b[38;5;34m128\u001b[0m │ conv2d_318[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_251   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m37\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_186         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m37\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_25… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_319 (\u001b[38;5;33mConv2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m37\u001b[0m,    │     \u001b[38;5;34m18,496\u001b[0m │ dropout_186[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m37\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_319[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_320 (\u001b[38;5;33mConv2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m37\u001b[0m,    │     \u001b[38;5;34m36,928\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m37\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_320[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_252   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m18\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_187         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m18\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_25… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_321 (\u001b[38;5;33mConv2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m18\u001b[0m,    │     \u001b[38;5;34m73,856\u001b[0m │ dropout_187[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m18\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_321[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_322 (\u001b[38;5;33mConv2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m18\u001b[0m,    │    \u001b[38;5;34m147,584\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m18\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_322[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_253   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m128\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_188         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m128\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_25… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_323 (\u001b[38;5;33mConv2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m256\u001b[0m) │    \u001b[38;5;34m295,168\u001b[0m │ dropout_188[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m256\u001b[0m) │      \u001b[38;5;34m1,024\u001b[0m │ conv2d_323[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_254   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_52          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_25… │\n",
       "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_144 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │  \u001b[38;5;34m2,097,664\u001b[0m │ flatten_52[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_189         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_144[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_145 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m32,832\u001b[0m │ dropout_189[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_146 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m65,664\u001b[0m │ dropout_189[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_190         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_145[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_191         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_146[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ hour_output (\u001b[38;5;33mDense\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)        │        \u001b[38;5;34m780\u001b[0m │ dropout_190[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ minute_output       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)        │      \u001b[38;5;34m7,740\u001b[0m │ dropout_191[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,779,720</span> (10.60 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,779,720\u001b[0m (10.60 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,778,376</span> (10.60 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,778,376\u001b[0m (10.60 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,344</span> (5.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,344\u001b[0m (5.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-fresh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
